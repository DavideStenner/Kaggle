{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.2.1.\u001b[31m9000\u001b[39m     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.2     \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 2.1.3          \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 0.8.3     \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.0.0          \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0     \n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1          \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.4.0     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "\n",
      "Attaching package: ‘data.table’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    transpose\n",
      "\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Registered S3 method overwritten by 'xts':\n",
      "  method     from\n",
      "  as.zoo.xts zoo \n",
      "\n",
      "\n",
      "Attaching package: ‘xts’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Registered S3 methods overwritten by 'forecast':\n",
      "  method             from    \n",
      "  fitted.fracdiff    fracdiff\n",
      "  residuals.fracdiff fracdiff\n",
      "\n",
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:data.table’:\n",
      "\n",
      "    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n",
      "    yday, year\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    date\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘mltools’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    replace_na\n",
      "\n",
      "\n",
      "Loading required package: Metrics\n",
      "\n",
      "\n",
      "Attaching package: ‘Metrics’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:mltools’:\n",
      "\n",
      "    mse, msle, rmse, rmsle\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:forecast’:\n",
      "\n",
      "    accuracy\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'building_metadata.csv'</li>\n",
       "\t<li>'sample_submission.csv'</li>\n",
       "\t<li>'test.csv'</li>\n",
       "\t<li>'train.csv'</li>\n",
       "\t<li>'weather_test.csv'</li>\n",
       "\t<li>'weather_train.csv'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'building\\_metadata.csv'\n",
       "\\item 'sample\\_submission.csv'\n",
       "\\item 'test.csv'\n",
       "\\item 'train.csv'\n",
       "\\item 'weather\\_test.csv'\n",
       "\\item 'weather\\_train.csv'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'building_metadata.csv'\n",
       "2. 'sample_submission.csv'\n",
       "3. 'test.csv'\n",
       "4. 'train.csv'\n",
       "5. 'weather_test.csv'\n",
       "6. 'weather_train.csv'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"building_metadata.csv\" \"sample_submission.csv\" \"test.csv\"             \n",
       "[4] \"train.csv\"             \"weather_test.csv\"      \"weather_train.csv\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse) # metapackage with lots of helpful functions\n",
    "library(data.table)\n",
    "library(DT)\n",
    "library(readxl)\n",
    "library(dplyr)\n",
    "library(data.table)\n",
    "library(xts)\n",
    "library(forecast)\n",
    "library(lubridate)\n",
    "library(data.table)\n",
    "library(mltools)\n",
    "library(tseries)\n",
    "library(TTR)\n",
    "library(stats)\n",
    "library(reticulate)\n",
    "library(data.table)\n",
    "library(dplyr)\n",
    "require(lubridate)\n",
    "require(stringr)\n",
    "require(Metrics)\n",
    "require(zoo)\n",
    "library(rhdf5)\n",
    "\n",
    "path = '../input/ashrae-energy-prediction/'\n",
    "ucf_root = '../input/ashrae-ucf-spider-and-eda-full-test-labels/'\n",
    "ucl_root ='../input/ucl-data-leakage-episode-2/'\n",
    "asu_root ='../input/asu-kernel-leach/'\n",
    "cor_root ='../input/ashrae-site15-cornell/'\n",
    "\n",
    "leak = FALSE\n",
    "tolag = FALSE\n",
    "to_diff = FALSE\n",
    "to_log = FALSE\n",
    "\n",
    "list.files(path = path)\n",
    "logger = function(x){\n",
    "    return(sign(x)*log(1+abs(x)))\n",
    "}\n",
    "differ = function(x,n=1){\n",
    "    l = logger(x)\n",
    "    return(l-shift(l,n))\n",
    "}\n",
    "\n",
    "relative_temp =function(TD,T){\n",
    "    return(100*exp((17.625*TD)/(243.04+TD))/exp((17.625*T)/(243.04+T)))\n",
    "}\n",
    "farenhait_converter = function(T){\n",
    "    return(T*1.8+32)\n",
    "}\n",
    "celsius_converter = function(T){\n",
    "    return((T-32)/1.8)\n",
    "}\n",
    "heat_index = function(T,RH){\n",
    "    T = farenhait_converter(T)\n",
    "    HI = -42.379 + 2.04901523*T + 10.14333127*RH - .22475541*T*RH - .00683783*T*T - .05481717*RH*RH + .00122874*T*T*RH + .00085282*T*RH*RH - .00000199*T*T*RH*RH\n",
    "    return(HI)#celsius_converter(HI))\n",
    "}\n",
    "trunc <- function(x, prec = 1,...) base::trunc(x * 10^prec, ...) / 10^prec;\n",
    "\n",
    "weight_average = function(x){\n",
    "    len=length(x)\n",
    "    weight = seq(1,len)/(len*(len+1)/2)\n",
    "    return(trunc(sum(x*weight)))\n",
    "}\n",
    "wind_converter <- function(x){\n",
    "    return(2.23694*x)\n",
    "}\n",
    "wind_chill =function(v,t){\n",
    "    t = farenhait_converter(t)\n",
    "    v = wind_converter(v)\n",
    "    return(ifelse(v>=3 & t<=50,35.74 + (0.6215 * t) - 35.75 * (v^0.16) + 0.4275 * t * v^0.16,NA))\n",
    "}\n",
    "feel_like = function(v,t,rh){\n",
    "    tf = farenhait_converter(t)\n",
    "    vf = wind_converter(v)\n",
    "    res = tf\n",
    "    if(length(which(tf<=50 & vf>=3))>0){\n",
    "        res[which(tf<=50 & vf>=3)] <- wind_chill(v[which(tf<=50 & vf>=3)],t[which(tf<=50 & vf>=3)])\n",
    "    }\n",
    "    if(length(which(tf>=80))){\n",
    "        res[which(tf>=80)] <- heat_index(t[which(tf>=80)],rh[which(tf>=80)])\n",
    "    }\n",
    "    return(res)\n",
    "}\n",
    "freq_na_calc <- function(x){\n",
    "    na_num = sum(is.na(x))\n",
    "    tab = table(x)\n",
    "    if(na_num==length(x)){\n",
    "        return(NA)\n",
    "    }\n",
    "    if(na_num >max(tab)){\n",
    "        return(NA)\n",
    "    }else{\n",
    "        return(as.numeric(names(which.max(table(temp2)))))\n",
    "    }\n",
    "}\n",
    "weight_average_simmery <- function(x,pos){\n",
    "    len=length(x)-1\n",
    "    weight = c(seq(1,pos-1)/(len*(len+1)/4),seq(pos-1,1)/(len*(len+1)/4))\n",
    "    rebalance = sum(weight*(!is.na(x[-pos])))\n",
    "    weight = weight[(!is.na(x[-pos]))]/rebalance\n",
    "    return(round(sum(x[-pos][(!is.na(x[-pos]))]*weight),0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "xtrain <- fread(paste(path,'train.csv',sep=''))\n",
    "weather_train = fread(paste(path,'weather_train.csv',sep=''))\n",
    "weather_test = fread(paste(path,'weather_test.csv',sep=''))\n",
    "building_metadata = fread(paste(path,'building_metadata.csv',sep=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the column we need to know what to drop \n",
    "# xtrain$tokeep <- 0\n",
    "\n",
    "# ## detect the strings of zeroes ----\n",
    "\n",
    "# # list of unique buildings \n",
    "# building_list <- unique(xtrain$building_id)\n",
    "\n",
    "\n",
    "# for (bb in building_list){\n",
    "#     index0 <- which(xtrain$building_id == bb)\n",
    "#     x0 <- xtrain[index0,]\n",
    "#     x0[, ':='(rmx = rollmean(meter_reading, k = 50, partial = TRUE, fill = 0, align = 'right')),\n",
    "#            by= list(meter)]\n",
    "#     idx <- which(x0$rmx < .5)\n",
    "#     xtrain$tokeep[index0[-idx]] <- 1\n",
    "#     print(paste(bb, ': ', round(1-length(idx)/nrow(x0),2), ' kept', sep = ''))\n",
    "# }\n",
    "\n",
    "# xtr <- xtrain[xtrain$tokeep == 1,]\n",
    "# xtr$tokeep <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORRECT RANGE FOR PHYSICAL DATA\n",
    "#Wind speed can't be less than zero\n",
    "# weather_train$wind_speed[weather_train$wind_speed<0] = 0\n",
    "\n",
    "# weather_test$wind_speed[weather_test$wind_speed<0] = 0\n",
    "\n",
    "# #Wind direction should be in range [0,360] --> correct by compass\n",
    "# weather_train$wind_direction[weather_train$wind_direction>360] = weather_train$wind_direction[weather_train$wind_direction>360]-360\n",
    "# weather_test$wind_direction[weather_test$wind_direction>360] = weather_test$wind_direction[weather_test$wind_direction>360]-360\n",
    "\n",
    "# weather_train$wind_direction[weather_train$wind_direction<0] = 360 - weather_train$wind_direction[weather_train$wind_direction<0]\n",
    "# weather_test$wind_direction[weather_test$wind_direction<0] = 360 - weather_test$wind_direction[weather_test$wind_direction<0]\n",
    "\n",
    "weather_train$wind_direction[weather_train$wind_direction==360]=0\n",
    "weather_test$wind_direction[weather_test$wind_direction==360]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing for site 0 :  0 \n",
      "Number of Missing for site 1 :  21 \n",
      "Number of Missing for site 2 :  1 \n",
      "Number of Missing for site 3 :  4 \n",
      "Number of Missing for site 4 :  1 \n",
      "Number of Missing for site 5 :  29 \n",
      "Number of Missing for site 6 :  2 \n",
      "Number of Missing for site 7 :  170 \n",
      "Number of Missing for site 8 :  0 \n",
      "Number of Missing for site 9 :  4 \n",
      "Number of Missing for site 10 :  2 \n",
      "Number of Missing for site 11 :  170 \n",
      "Number of Missing for site 12 :  29 \n",
      "Number of Missing for site 13 :  1 \n",
      "Number of Missing for site 14 :  7 \n",
      "Number of Missing for site 15 :  330 \n",
      "----------------------------------\n",
      "Number of Missing for site 0 :  0 \n",
      "Number of Missing for site 1 :  233 \n",
      "Number of Missing for site 2 :  0 \n",
      "Number of Missing for site 3 :  3 \n",
      "Number of Missing for site 4 :  4 \n",
      "Number of Missing for site 5 :  279 \n",
      "Number of Missing for site 6 :  16 \n",
      "Number of Missing for site 7 :  947 \n",
      "Number of Missing for site 8 :  0 \n",
      "Number of Missing for site 9 :  39 \n",
      "Number of Missing for site 10 :  44 \n",
      "Number of Missing for site 11 :  947 \n",
      "Number of Missing for site 12 :  241 \n",
      "Number of Missing for site 13 :  1 \n",
      "Number of Missing for site 14 :  4 \n",
      "Number of Missing for site 15 :  319 \n"
     ]
    }
   ],
   "source": [
    "siter = sort(unique(weather_train$site_id))\n",
    "weather_train$timestamp = as.POSIXct(weather_train$timestamp)\n",
    "weather_test$timestamp = as.POSIXct(weather_test$timestamp)\n",
    "\n",
    "time_train_filter = max(weather_train$timestamp)\n",
    "\n",
    "#cange weather_train\n",
    "original_time = seq(min(weather_train$timestamp),max(weather_train$timestamp),by='1 hour')\n",
    "\n",
    "for(site in siter){\n",
    "    cat('Number of Missing for site',site,': ',length(original_time)-sum(weather_train$site_id==site),'\\n')\n",
    "}\n",
    "\n",
    "cat('----------------------------------\\n')\n",
    "original_time = seq(min(weather_test$timestamp),max(weather_test$timestamp),by='1 hour')\n",
    "\n",
    "for(site in siter){\n",
    "    cat('Number of Missing for site',site,': ',length(original_time)-sum(weather_test$site_id==site),'\\n')\n",
    "}\n",
    "\n",
    "#return to char for left join\n",
    "weather_train$timestamp = as.character(weather_train$timestamp)\n",
    "weather_test$timestamp = as.character(weather_test$timestamp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train$timestamp = as.POSIXct(weather_train$timestamp)\n",
    "weather_test$timestamp = as.POSIXct(weather_test$timestamp)\n",
    "time_seq = seq(min(weather_train$timestamp),max(weather_test$timestamp)+10*60*60,by='1 hour')\n",
    "site_id = rep(siter,each=length(time_seq))\n",
    "\n",
    "weather_train = data.frame(weather_train,to_corr=1)\n",
    "weather_test = data.frame(weather_test,to_corr=1)\n",
    "\n",
    "weather_all = left_join(data.frame(site_id = site_id,timestamp = time_seq),rbind.data.frame(weather_train,weather_test),\n",
    "                       by=c('site_id'='site_id','timestamp'='timestamp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_vec<- weather_all$to_corr\n",
    "weather_all <- weather_all[,-ncol(weather_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_train = data.frame(weather_train)\n",
    "# for(site in siter){\n",
    "#     pos_all_site = which(weather_train$site_id==site)\n",
    "#     for(car in 1:ncol(weather_train)){\n",
    "#         if(mean(is.na(weather_train[pos_all_site,car]))>0){\n",
    "#             cat('Number of Missing for site',site,', col ',names(weather_train)[car],' : ',mean(is.na(weather_train[pos_all_site,car])),'\\n')\n",
    "#         }\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing for site 0 , col  cloud_coverage  :  0.4325834 \n",
      "Number of Missing for site 1 , col  cloud_coverage  :  0.7980163 \n",
      "Number of Missing for site 1 , col  precip_depth_1_hr  :  1 \n",
      "Number of Missing for site 2 , col  cloud_coverage  :  0.2968002 \n",
      "Number of Missing for site 3 , col  cloud_coverage  :  0.4374097 \n",
      "Number of Missing for site 4 , col  cloud_coverage  :  0.4664817 \n",
      "Number of Missing for site 5 , col  cloud_coverage  :  0.6723797 \n",
      "Number of Missing for site 5 , col  precip_depth_1_hr  :  1 \n",
      "Number of Missing for site 5 , col  sea_level_pressure  :  1 \n",
      "Number of Missing for site 6 , col  cloud_coverage  :  0.3605685 \n",
      "Number of Missing for site 7 , col  cloud_coverage  :  1 \n",
      "Number of Missing for site 7 , col  precip_depth_1_hr  :  0.9039295 \n",
      "Number of Missing for site 8 , col  cloud_coverage  :  0.4325834 \n",
      "Number of Missing for site 9 , col  cloud_coverage  :  0.426237 \n",
      "Number of Missing for site 9 , col  wind_direction  :  0.3044767 \n",
      "Number of Missing for site 10 , col  cloud_coverage  :  0.2882876 \n",
      "Number of Missing for site 11 , col  cloud_coverage  :  1 \n",
      "Number of Missing for site 11 , col  precip_depth_1_hr  :  0.9039295 \n",
      "Number of Missing for site 12 , col  precip_depth_1_hr  :  1 \n",
      "Number of Missing for site 13 , col  cloud_coverage  :  0.4980239 \n",
      "Number of Missing for site 14 , col  cloud_coverage  :  0.4231968 \n",
      "Number of Missing for site 15 , col  cloud_coverage  :  0.5708748 \n",
      "Number of Missing for site 15 , col  precip_depth_1_hr  :  0.7769628 \n"
     ]
    }
   ],
   "source": [
    "for(site in siter){\n",
    "    pos_all_site = which(weather_all$site_id==site)\n",
    "    for(car in 1:ncol(weather_all)){\n",
    "        if(mean(is.na(weather_all[pos_all_site,car]))>0.1){\n",
    "            cat('Number of Missing for site',site,', col ',names(weather_all)[car],' : ',mean(is.na(weather_all[pos_all_site,car])),'\\n')\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing for site 0 , col  air_temperature  :  0.05 \n",
      "Number of Missing for site 0 , col  dew_temperature  :  0.05 \n",
      "Number of Missing for site 0 , col  sea_level_pressure  :  1.54 \n",
      "Number of Missing for site 1 , col  air_temperature  :  1.09 \n",
      "Number of Missing for site 1 , col  dew_temperature  :  1.09 \n",
      "Number of Missing for site 1 , col  sea_level_pressure  :  1.45 \n",
      "Number of Missing for site 2 , col  air_temperature  :  0.05 \n",
      "Number of Missing for site 2 , col  dew_temperature  :  0.05 \n",
      "Number of Missing for site 2 , col  sea_level_pressure  :  0.33 \n",
      "Number of Missing for site 3 , col  air_temperature  :  0.09 \n",
      "Number of Missing for site 3 , col  dew_temperature  :  0.1 \n",
      "Number of Missing for site 3 , col  sea_level_pressure  :  2.09 \n",
      "Number of Missing for site 4 , col  air_temperature  :  0.06 \n",
      "Number of Missing for site 4 , col  dew_temperature  :  0.08 \n",
      "Number of Missing for site 4 , col  sea_level_pressure  :  0.79 \n",
      "Number of Missing for site 5 , col  air_temperature  :  1.22 \n",
      "Number of Missing for site 5 , col  dew_temperature  :  1.22 \n",
      "Number of Missing for site 5 , col  sea_level_pressure  :  100 \n",
      "Number of Missing for site 6 , col  air_temperature  :  0.16 \n",
      "Number of Missing for site 6 , col  dew_temperature  :  0.16 \n",
      "Number of Missing for site 6 , col  sea_level_pressure  :  2.25 \n",
      "Number of Missing for site 7 , col  air_temperature  :  4.28 \n",
      "Number of Missing for site 7 , col  dew_temperature  :  4.56 \n",
      "Number of Missing for site 7 , col  sea_level_pressure  :  4.47 \n",
      "Number of Missing for site 8 , col  air_temperature  :  0.05 \n",
      "Number of Missing for site 8 , col  dew_temperature  :  0.05 \n",
      "Number of Missing for site 8 , col  sea_level_pressure  :  1.54 \n",
      "Number of Missing for site 9 , col  air_temperature  :  0.43 \n",
      "Number of Missing for site 9 , col  dew_temperature  :  0.86 \n",
      "Number of Missing for site 9 , col  sea_level_pressure  :  3.24 \n",
      "Number of Missing for site 10 , col  air_temperature  :  0.33 \n",
      "Number of Missing for site 10 , col  dew_temperature  :  0.35 \n",
      "Number of Missing for site 10 , col  sea_level_pressure  :  2.09 \n",
      "Number of Missing for site 11 , col  air_temperature  :  4.28 \n",
      "Number of Missing for site 11 , col  dew_temperature  :  4.56 \n",
      "Number of Missing for site 11 , col  sea_level_pressure  :  4.47 \n",
      "Number of Missing for site 12 , col  air_temperature  :  1.06 \n",
      "Number of Missing for site 12 , col  dew_temperature  :  1.06 \n",
      "Number of Missing for site 12 , col  sea_level_pressure  :  1.39 \n",
      "Number of Missing for site 13 , col  air_temperature  :  0.06 \n",
      "Number of Missing for site 13 , col  dew_temperature  :  0.06 \n",
      "Number of Missing for site 13 , col  sea_level_pressure  :  1.28 \n",
      "Number of Missing for site 14 , col  air_temperature  :  0.09 \n",
      "Number of Missing for site 14 , col  dew_temperature  :  0.09 \n",
      "Number of Missing for site 14 , col  sea_level_pressure  :  1.43 \n",
      "Number of Missing for site 15 , col  air_temperature  :  2.54 \n",
      "Number of Missing for site 15 , col  dew_temperature  :  2.56 \n",
      "Number of Missing for site 15 , col  sea_level_pressure  :  8.05 \n"
     ]
    }
   ],
   "source": [
    "#CORRECT MISSING FOR ALL EXCEPT CLOUD COVERAGE AND PRECIPIT WHICH HAS NATURALLY MISSING VALUES.\n",
    "\n",
    "to_corr = which(names(weather_all)%in%c('air_temperature','dew_temperature','sea_level_pressure'))\n",
    "siter = sort(unique(weather_all$site_id))\n",
    "for(site in siter){\n",
    "    pos_all_site = which(weather_all$site_id==site)\n",
    "    for(car in to_corr){\n",
    "        cat('Number of Missing for site',site,', col ',names(weather_all)[car],' : ',round(mean(is.na(weather_all[pos_all_site,car]))*100,2),'\\n')\n",
    "        if(mean(is.na(weather_all[pos_all_site,car]))<.4){\n",
    "            weather_all[pos_all_site,car] = round(na.interp(ts(weather_all[pos_all_site,car],frequency=24)),1)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPONENTIAL BACK AND FORWARD APROXIMATION \n",
    "\n",
    "to_corr = which(names(weather_all)%in%c('wind_direction','wind_speed'))\n",
    "siter = sort(unique(weather_all$site_id))\n",
    "window = 10\n",
    "for(site in siter){\n",
    "    pos_site = which(weather_all$site_id==site)\n",
    "    for(car in to_corr){\n",
    "        pos = which(is.na(weather_all[pos_site,car]))\n",
    "        for(i in pos){\n",
    "            if(i>window & i<(max(pos_site)-window)){\n",
    "                micro_series = weather_all[pos_site[seq(i-window,i+window)],car]\n",
    "                weather_all[pos_site[i],car]=weight_average_simmery(micro_series,window+1)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#MEAN BY HOUR AND MONTH FOR REMAINING MISSING VALUES\n",
    "\n",
    "month_t = month(weather_all$timestamp)\n",
    "day_t = day(weather_all$timestamp) \n",
    "for(site in siter){\n",
    "    pos_site = which(weather_all$site_id==site)\n",
    "    temp = weather_all[pos_site,]\n",
    "    month_t_temp = month_t[pos_site]\n",
    "    day_t_temp = day_t[pos_site]\n",
    "    for(car in to_corr){\n",
    "        pos = which(is.na(temp[,car]))\n",
    "        if(length(pos)>0){\n",
    "            for(i in pos){\n",
    "                temp2 = na.omit(temp[month_t_temp==month_t_temp[i] & day_t_temp == day_t_temp[i],car])\n",
    "                weather_all[pos_site[i],car]=round(mean(temp2))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLOUD AS MOST FREQUENT VALUES WITH ALSO MISSING\n",
    "\n",
    "\n",
    "to_corr = which(names(weather_all)%in%c('cloud_coverage','precip_depth_1_hr'))\n",
    "siter = sort(unique(weather_all$site_id))\n",
    "\n",
    "month_t = month(weather_all$timestamp)\n",
    "day_t = day(weather_all$timestamp) \n",
    "# res <- c()\n",
    "for(site in siter){\n",
    "    pos_site = which(weather_all$site_id==site)\n",
    "    temp = weather_all[pos_site,]\n",
    "    month_t_temp = month_t[pos_site]\n",
    "    day_t_temp = day_t[pos_site]\n",
    "    dum_temp = dum_vec[pos_site]\n",
    "    for(car in to_corr){\n",
    "        pos = which(is.na(dum_temp))\n",
    "        if(length(pos)>0){\n",
    "            for(i in pos){\n",
    "                temp2 = temp[month_t_temp==month_t_temp[i] & day_t_temp == day_t_temp[i] & (!is.na(dum_temp)),car]\n",
    "#                 res<-c(res,freq_na_calc(temp2))\n",
    "                weather_all[pos_site[i],car]=freq_na_calc(temp2)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check outlier\n",
    "# to_corr = which(names(weather_all)%in%c('sea_level_pressure','wind_speed')) #'air_temperature','dew_temperature','wind_direction',\n",
    "# siter = sort(unique(weather_all$site_id))\n",
    "# for(site in siter){\n",
    "#     pos_all_site = which(weather_all$site_id==site)\n",
    "#     for(car in to_corr){\n",
    "#         if(mean(is.na(weather_all[pos_all_site,car]))<.4){\n",
    "#             out = tsoutliers(ts(weather_all[pos_all_site,car],frequency=24))\n",
    "#             if(length(out$index)>0){\n",
    "#                 cat('Number of Outlier for site',site,', col ',names(weather_all)[car],' : ',length(out$index),'\\n')\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_all$timestamp = as.character(weather_all$timestamp)\n",
    "\n",
    "weather_train = data.table(weather_all[weather_all$timestamp<=time_train_filter,])\n",
    "weather_test = data.table(weather_all[weather_all$timestamp>time_train_filter,])\n",
    "\n",
    "rm(weather_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_metadata[,c('age_built'):=list(2019-year_built)][,year_built:=NULL]\n",
    "#,'new_century_built' ,as.numeric(year_built>2000)  trunc(logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN INFORMATION FOR BUILD BY SITE ID AND OTHER\n",
    "\n",
    "# building_metadata[,c('square_feat_mean_site','age_built_mean_site',\n",
    "#                      'new_century_built_mean_site'):=list(trunc(mean(logger(square_feet),na.rm=T),4),\n",
    "#                                                           trunc(mean(logger(age_built),na.rm=T),4),\n",
    "#                                                           trunc(mean(logger(new_century_built),na.rm=T),4)),by=site_id]\n",
    "# building_metadata[,c('square_feat_mean_primary','age_built_mean_primary',\n",
    "#                      'new_century_built_mean_primary'):=list(trunc(mean(logger(square_feet),na.rm=T),4),\n",
    "#                                                              trunc(mean(logger(age_built),na.rm=T),4),\n",
    "#                                                              trunc(mean(logger(new_century_built),na.rm=T),4)),by=primary_use]\n",
    "# building_metadata[,c('square_feat_mean_primary_site','age_built_mean_primary_site',\n",
    "#                      'new_century_built_mean_primary_site'):=list(trunc(mean(logger(square_feet),na.rm=T),4),\n",
    "#                                                                   trunc(mean(logger(age_built),na.rm=T),4),\n",
    "#                                                                   trunc(mean(logger(new_century_built),na.rm=T),4)),\n",
    "#                   by=list(site_id,primary_use)]\n",
    "\n",
    "building_metadata$square_feet = logger(building_metadata$square_feet)\n",
    "building_metadata$primary_use = as.numeric(as.factor(building_metadata$primary_use))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=weather_train[,list(air_temperature=mean(is.na(air_temperature)),dew_temperature=mean(is.na(air_temperature)),\n",
    "#                     cloud_coverage=mean(is.na(cloud_coverage)),\n",
    "#                     precip_depth_1_hr=mean(is.na(precip_depth_1_hr)),\n",
    "#                     sea_level_pressure=mean(is.na(sea_level_pressure)),\n",
    "#                     wind_direction=mean(is.na(wind_direction)),wind_speed=mean(is.na(wind_speed))),by=site_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = weather_test[,list(air_temperature=mean(is.na(air_temperature)),dew_temperature=mean(is.na(air_temperature)),\n",
    "#                     cloud_coverage=mean(is.na(cloud_coverage)),\n",
    "#                     precip_depth_1_hr=mean(is.na(precip_depth_1_hr)),\n",
    "#                     sea_level_pressure=mean(is.na(sea_level_pressure)),\n",
    "#                     wind_direction=mean(is.na(wind_direction)),wind_speed=mean(is.na(wind_speed))),by=site_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOME SITE HAS ALL RELEVATION MISSING --> CREATE DUMMY\n",
    "\n",
    "# weather_train[,c('has_cloud','has_rain','has_sea','precipit_long') := list(\n",
    "#                                         ifelse(weather_train$site_id%in%b$site_id[a$cloud_coverage==1],1,0),\n",
    "#                                         ifelse(weather_train$site_id%in%b$site_id[a$precip_depth_1_hr==1],1,0),\n",
    "#                                         ifelse(weather_train$site_id%in%b$site_id[a$sea_level_pressure==1],1,0),\n",
    "#                                         ifelse(weather_train$precip_depth_1_hr==(-1),1,0))]\n",
    "# weather_test[,c('has_cloud','has_rain','has_sea','precipit_long') := list(\n",
    "#                                         ifelse(weather_test$site_id%in%b$site_id[b$cloud_coverage==1],1,0),\n",
    "#                                         ifelse(weather_test$site_id%in%b$site_id[b$precip_depth_1_hr==1],1,0),\n",
    "#                                         ifelse(weather_test$site_id%in%b$site_id[b$sea_level_pressure==1],1,0),\n",
    "#                                         ifelse(weather_test$precip_depth_1_hr==(-1),1,0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERY MISSING IN TO CORR ARE CORRECTED WITH WEIGHTED MEAN BY DECAYING FACTOR TO GIVE BETTER IMPORTANCE TO RECENT OBSERVATION\n",
    "\n",
    "# to_corr = which(names(weather_train)%in%c('air_temperature','dew_temperature','sea_level_pressure','wind_direction','wind_speed'))\n",
    "# siter = unique(weather_train$site_id)\n",
    "# weather_train = data.frame(weather_train)\n",
    "# for(site in siter){\n",
    "#     pos_site = which(weather_train$site_id==site)\n",
    "#     for(car in to_corr){\n",
    "#         pos = which(is.na(weather_train[pos_site,car]))\n",
    "#         for(i in pos){\n",
    "#             if(i>5){\n",
    "#                 micro_series = na.omit(weather_train[pos_site[seq(i-5,i)],car])\n",
    "#                 if(length(micro_series)>0){\n",
    "#                     weather_train[pos_site[i],car]=weight_average(micro_series)#mean(weather_train[pos_site[seq(i-3,i)],car],na.rm=T)\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVERY MISSING IN TO CORR ARE CORRECTED WITH WEIGHTED MEAN BY DECAYING FACTOR TO GIVE BETTER IMPORTANCE TO RECENT OBSERVATION\n",
    "\n",
    "# to_corr = which(names(weather_test)%in%c('air_temperature','dew_temperature','sea_level_pressure','wind_direction','wind_speed'))\n",
    "# siter = unique(weather_test$site_id)\n",
    "# weather_test = data.frame(weather_test)\n",
    "# for(site in siter){\n",
    "#     pos_site = which(weather_test$site_id==site)\n",
    "#     for(car in to_corr){\n",
    "#         pos = which(is.na(weather_test[pos_site,car]))\n",
    "#         for(i in pos){\n",
    "#             if(i>5){\n",
    "#                 micro_series = na.omit(weather_test[pos_site[seq(i-5,i)],car])\n",
    "#                 if(length(micro_series)>0){\n",
    "#                     weather_test[pos_site[i],car]=weight_average(micro_series)#mean(weather_train[pos_site[seq(i-3,i)],car],na.rm=T)\n",
    "#                 }\n",
    "#             }\n",
    "            \n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# weather_train = weather_train[-which(is.na(weather_train$wind_direction)),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIND DIRECTION COMPASS\n",
    "beaufort = c(0, 0.3, 1.6, 3.4, 5.5, 8, 10.8, 13.9, 17.2, 20.8, 24.5, 28.5, 33)\n",
    "\n",
    "weather_train$wind_compass = round(weather_train$wind_direction/22.5 +.5)%%16\n",
    "weather_test$wind_compass = round(weather_test$wind_direction/22.5 +.5)%%16\n",
    "\n",
    "#BEAUFORT SCALE\n",
    "weather_train$beaufort_scale = as.numeric(cut(weather_train$wind_speed,breaks = beaufort))\n",
    "weather_test$beaufort_scale = as.numeric(cut(weather_test$wind_speed,breaks = beaufort))\n",
    "\n",
    "\n",
    "#RELATIVE HUMIDITY\n",
    "weather_train$relative_humidity =  relative_temp(weather_train$dew_temperature,weather_train$air_temperature)\n",
    "weather_test$relative_humidity = relative_temp(weather_test$dew_temperature,weather_test$air_temperature)\n",
    "\n",
    "#HEAT INDEX\n",
    "weather_train$heat_index =  heat_index(weather_train$air_temperature,weather_train$relative_humidity)\n",
    "weather_test$heat_index = heat_index(weather_test$air_temperature,weather_test$relative_humidity)\n",
    "\n",
    "weather_train$wind_chill =  wind_chill(weather_train$wind_speed,weather_train$air_temperature)\n",
    "weather_test$wind_chill = wind_chill(weather_test$wind_speed,weather_test$air_temperature)\n",
    "\n",
    "weather_train$wind_load =  weather_train$sea_level_pressure*(weather_train$wind_speed^2)\n",
    "weather_test$wind_load = weather_test$sea_level_pressure*(weather_test$wind_speed^2)\n",
    "\n",
    "weather_train$temp_diff =  weather_train$dew_temperature-weather_train$air_temperature\n",
    "weather_test$temp_diff = weather_test$dew_temperature-weather_test$air_temperature\n",
    "\n",
    "weather_train$feel = feel_like(weather_train$wind_speed,weather_train$air_temperature,weather_train$relative_humidity)\n",
    "weather_test$feel = feel_like(weather_test$wind_speed,weather_test$air_temperature,weather_test$relative_humidity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_chill =function(v,t){\n",
    "    t = farenhait_converter(t)\n",
    "    v = wind_converter(v)\n",
    "    return(ifelse(v>=3 & t<=50,35.74 + (0.6215 * t) - 35.75 * (v^0.16) + 0.4275 * t * v^0.16,NA))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = nrow(weather_train)\n",
    "to_corr = which(names(weather_train)%in%c('air_temperature','dew_temperature','sea_level_pressure',\n",
    "                                         'relative_humidity','wind_speed','heat_index','wind_chill','wind_load','temp_diff'))\n",
    "To_erase = c()\n",
    "n=1\n",
    "weather_train = data.frame(weather_train)\n",
    "weather_test = data.frame(weather_test)\n",
    "\n",
    "if(to_diff){\n",
    "    for(site in unique(weather_train$site_id)){\n",
    "        To_erase = c(To_erase,which(weather_train$site_id==site)[1:n])\n",
    "        for(car in to_corr){\n",
    "            train_temp = weather_train[weather_train$site_id==site,car]\n",
    "            train_temp_pos = length(train_temp) \n",
    "            test_temp = weather_test[weather_test$site_id==site,car]\n",
    "            temp = c(train_temp,test_temp)\n",
    "            calc_temp = differ(temp,n=n)#trunc(logger(temp),4)\n",
    "            weather_train[weather_train$site_id==site,car] = calc_temp[1:train_temp_pos]\n",
    "            weather_test[weather_test$site_id==site,car] = calc_temp[(train_temp_pos+1):length(temp)]\n",
    "        }\n",
    "    }\n",
    "    rm(list=c('train_temp','test_temp','temp','calc_temp'))\n",
    "\n",
    "}\n",
    "if(to_log){\n",
    "    for(site in unique(weather_train$site_id)){\n",
    "        To_erase = c(To_erase,which(weather_train$site_id==site)[1:n])\n",
    "        for(car in to_corr){\n",
    "            train_temp = weather_train[weather_train$site_id==site,car]\n",
    "            train_temp_pos = length(train_temp) \n",
    "            test_temp = weather_test[weather_test$site_id==site,car]\n",
    "            temp = c(train_temp,test_temp)\n",
    "            calc_temp = logger(temp)#\n",
    "            weather_train[weather_train$site_id==site,car] = calc_temp[1:train_temp_pos]\n",
    "            weather_test[weather_test$site_id==site,car] = calc_temp[(train_temp_pos+1):length(temp)]\n",
    "        }\n",
    "    }\n",
    "    rm(list=c('train_temp','test_temp','temp','calc_temp'))\n",
    "\n",
    "}\n",
    "# weather_train = weather_train[-To_erase,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(tolag==TRUE){\n",
    "    to_lag = c('air_temperature','cloud_coverage','dew_temperature','precip_depth_1_hr','sea_level_pressure','wind_direction','wind_speed',\n",
    "               'wind_compass','beaufort_scale','relative_humidity','heat_index','wind_chill','wind_load','temp_diff')\n",
    "    train_pos = nrow(weather_train)\n",
    "    To_erase = c()\n",
    "    n=1\n",
    "\n",
    "    weather_train[,paste(to_lag,'lag_24',sep='_')]=0\n",
    "    weather_train[,paste(to_lag,'lag_48',sep='_')]=0\n",
    "\n",
    "    weather_test[,paste(to_lag,'lag_24',sep='_')]=0\n",
    "    weather_test[,paste(to_lag,'lag_48',sep='_')]=0\n",
    "\n",
    "    for(site in unique(weather_train$site_id)){\n",
    "        To_erase = c(To_erase,which(weather_train$site_id==site)[1:49])\n",
    "        for(car in to_lag){\n",
    "            train_temp = weather_train[weather_train$site_id==site,car]\n",
    "            train_temp_pos = length(train_temp) \n",
    "            test_temp = weather_test[weather_test$site_id==site,car]\n",
    "            temp = c(train_temp,test_temp)\n",
    "            calc_temp_24 = data.table::shift(temp,24)\n",
    "            calc_temp_48 = data.table::shift(temp,48)\n",
    "\n",
    "            weather_train[weather_train$site_id==site,paste(car,'lag_24',sep='_')] = calc_temp_24[1:train_temp_pos]\n",
    "            weather_test[weather_test$site_id==site,paste(car,'lag_24',sep='_')] = calc_temp_24[(train_temp_pos+1):length(temp)]\n",
    "\n",
    "            weather_train[weather_train$site_id==site,paste(car,'lag_48',sep='_')] = calc_temp_48[1:train_temp_pos]\n",
    "            weather_test[weather_test$site_id==site,paste(car,'lag_48',sep='_')] = calc_temp_48[(train_temp_pos+1):length(temp)]\n",
    "\n",
    "        }\n",
    "    }\n",
    "    weather_train <- weather_train[-To_erase,]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fread(paste(path,'train.csv',sep=''))\n",
    "test = fread(paste(path,'test.csv',sep=''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(leak==TRUE){\n",
    "    \n",
    "#     leak_df_ucf = fread(paste(ucf_root,'site0.csv',sep=''))\n",
    "#     leak_df_ucf$meter_reading = leak_df_ucf$meter_reading_scraped\n",
    "#     leak_df_ucf[,c('meter_reading_original','meter_reading_scraped'):=list(NULL,NULL)]\n",
    "#     leak_df_ucf = leak_df_ucf[-which(is.na(leak_df_ucf$meter_reading)),]\n",
    "#     leak_df_ucf[leak_df_ucf$meter_reading < 0, 'meter_reading'] = 0\n",
    "#     leak_df_ucf = leak_df_ucf[year(leak_df_ucf$timestamp)> 2016,]\n",
    "#     leak_df_ucf = leak_df_ucf[,c('timestamp','building_id','meter','meter_reading')]\n",
    "\n",
    "#     leak_df_ucl = fread(paste(ucl_root,'site1.csv',sep=''))\n",
    "#     leak_df_ucl$meter_reading = leak_df_ucl$meter_reading_scraped\n",
    "#     leak_df_ucl[,c('meter_reading_scraped'):=list(NULL)]\n",
    "#     leak_df_ucl = leak_df_ucl[-which(is.na(leak_df_ucl$meter_reading)),]\n",
    "#     leak_df_ucl[leak_df_ucl$meter_reading < 0, 'meter_reading'] = 0\n",
    "#     leak_df_ucl = leak_df_ucl[year(leak_df_ucl$timestamp)> 2016,]\n",
    "#     leak_df_ucl = leak_df_ucl[,c('timestamp','building_id','meter','meter_reading')]\n",
    "\n",
    "#     leak_df_asu = fread(paste(asu_root,'site2.csv',sep=''))\n",
    "#     leak_df_asu = leak_df_asu[-which(is.na(leak_df_asu$meter_reading)),]\n",
    "#     leak_df_asu[leak_df_asu$meter_reading < 0, 'meter_reading'] = 0\n",
    "#     leak_df_asu = leak_df_asu[year(leak_df_asu$timestamp) > 2016,]\n",
    "#     leak_df_asu = leak_df_asu[,c('timestamp','building_id','meter','meter_reading')]\n",
    "\n",
    "\n",
    "#     leak_df_cor = fread(paste(cor_root,'site15.csv',sep=''))\n",
    "#     leak_df_cor[leak_df_cor$meter_reading < 0, 'meter_reading'] = 0\n",
    "#     leak_df_cor = leak_df_cor[year(leak_df_cor$timestamp) > 2016,]\n",
    "#     leak_df_cor = leak_df_cor[,c('timestamp','building_id','meter','meter_reading')]\n",
    "\n",
    "#     leak_df = rbind.data.frame(leak_df_ucf,leak_df_ucl,leak_df_asu,leak_df_cor)\n",
    "#     leak_df = unique(leak_df)\n",
    "#     leak_df = leak_df[order(timestamp,building_id,meter)]\n",
    "    library(feather)\n",
    "    leak_df = read_feather('../input/ashrae-leak-data-station/leak.feather')\n",
    "    leak_df$timestamp = as.character(leak_df$timestamp)\n",
    "    leak_df = leak_df[,c('building_id','meter','timestamp','meter_reading')]\n",
    "    train = rbind.data.frame(train,leak_df)\n",
    "    train = unique(train)\n",
    "    train = train[order(timestamp,building_id,meter)]\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[,diff_meter:=paste(sort(unique(meter)),collapse=''),by=building_id]\n",
    "test[,diff_meter:=paste(sort(unique(meter)),collapse=''),by=building_id]\n",
    "\n",
    "train$diff_meter = as.integer(as.factor(train$diff_meter))\n",
    "test$diff_meter = as.integer(as.factor(test$diff_meter))\n",
    "\n",
    "train[,building_meter:=paste(building_id,meter,sep='')]\n",
    "test[,building_meter:=paste(building_id,meter,sep='')]\n",
    "\n",
    "train$building_meter = as.integer(as.factor(train$building_meter))\n",
    "test$building_meter = as.integer(as.factor(test$building_meter))\n",
    "test[,row_id:=NULL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_now = nrow(train)\n",
    "all =rbind.data.frame(train[,c('building_id','meter','diff_meter','building_meter')],\n",
    "                      test[,c('building_id','meter','diff_meter','building_meter')])\n",
    "all[,c('building_id_count'):=list(.N/nrow(all)),by =building_id]\n",
    "all[,c('meter_count'):=list(.N/nrow(all)),by =meter]\n",
    "all[,c('diff_meter_count'):=list(.N/nrow(all)),by =diff_meter]\n",
    "all[,c('building_meter_count'):=list(.N/nrow(all)),by =building_meter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[,c('building_id_count','meter_count','diff_meter_count','building_meter_count')] = all[1:train_now,c('building_id_count','meter_count','diff_meter_count','building_meter_count')]\n",
    "test[,c('building_id_count','meter_count','diff_meter_count','building_meter_count')] = all[(train_now+1):nrow(all),c('building_id_count','meter_count','diff_meter_count','building_meter_count')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h5createFile(\"data.h5\")\n",
    "h5write(train, \"data.h5\",\"train\")\n",
    "h5write(test, \"data.h5\",\"test\")\n",
    "h5write(building_metadata, \"data.h5\",\"building_metadata\")\n",
    "h5write(weather_train, \"data.h5\",\"weather_train\")\n",
    "h5write(weather_test, \"data.h5\",\"weather_test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
