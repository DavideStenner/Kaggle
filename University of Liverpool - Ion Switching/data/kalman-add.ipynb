{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.0.3\r\n",
      "  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 4.9 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from pandas==1.0.3) (1.18.2)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas==1.0.3) (2019.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas==1.0.3) (2.8.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==1.0.3) (1.14.0)\r\n",
      "\u001b[31mERROR: pandas-profiling 2.5.0 has requirement pandas==0.25.3, but you'll have pandas 1.0.3 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mERROR: hypertools 0.6.2 has requirement scikit-learn<0.22,>=0.19.1, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: pandas\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 0.25.3\r\n",
      "    Uninstalling pandas-0.25.3:\r\n",
      "      Successfully uninstalled pandas-0.25.3\r\n",
      "Successfully installed pandas-1.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pykalman import KalmanFilter\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import signal\n",
    "import gc\n",
    "\n",
    "LEN_ = 4000\n",
    "n_classes = 11\n",
    "fs = 10000.0  # Sample frequency (Hz)\n",
    "f0 = 50.0  # Frequency to be removed from signal (Hz)\n",
    "Q = 100  # Quality factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notch Filter...\n",
      "\n",
      "Kalman-train estimate...\n",
      "\n",
      "Kalman-test estimate...\n",
      "\n",
      "CPU times: user 48min 17s, sys: 7.91 s, total: 48min 25s\n",
      "Wall time: 48min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def Kalman1D(observations,damping=1):\n",
    "    # To return the smoothed time series data\n",
    "    observation_covariance = damping\n",
    "    initial_value_guess = observations[0]\n",
    "    transition_matrix = 1\n",
    "    transition_covariance = 0.1\n",
    "\n",
    "    kf = KalmanFilter(\n",
    "            initial_state_mean=initial_value_guess,\n",
    "            initial_state_covariance=observation_covariance,\n",
    "            observation_covariance=observation_covariance,\n",
    "            transition_covariance=transition_covariance,\n",
    "            transition_matrices=transition_matrix\n",
    "        )\n",
    "    pred_state, state_cov = kf.smooth(observations)\n",
    "    pred_state, state_cov = pred_state.reshape((-1)), state_cov.reshape((-1))\n",
    "    return pred_state, state_cov\n",
    "\n",
    "def segmenter(shape_train, shape_test):\n",
    "    temp_train = np.zeros((shape_train[0]))\n",
    "    temp_test = np.zeros((shape_test[0]))\n",
    "\n",
    "    def point_train(batch):\n",
    "        a = 500000*(batch-1); b = 500000*batch\n",
    "        return(a, b)\n",
    "\n",
    "    #train\n",
    "    #1 slow\n",
    "    (a, b), (c, d) = point_train(1), point_train(2)\n",
    "    temp_train[a:b] = 1\n",
    "    temp_train[c:d] = 1\n",
    "    #1 fast\n",
    "    (a, b), (c, d) = point_train(3), point_train(7)\n",
    "    temp_train[a:b] = 2\n",
    "    temp_train[c:d] = 2\n",
    "    #3 \n",
    "    (a, b), (c, d) = point_train(4), point_train(8)\n",
    "    temp_train[a:b] = 3\n",
    "    temp_train[c:d] = 3\n",
    "    #5\n",
    "    (a, b), (c, d) = point_train(6), point_train(9)\n",
    "    temp_train[a:b] = 5\n",
    "    temp_train[c:d] = 5\n",
    "    #10\n",
    "    (a, b), (c, d) = point_train(5), point_train(10)\n",
    "    temp_train[a:b] = 10\n",
    "    temp_train[c:d] = 10\n",
    "\n",
    "    #test\n",
    "    def point_test(batch):\n",
    "        a, b = 100000*batch, 100000*(batch+1)\n",
    "        return(a, b)\n",
    "    \n",
    "    #SUB A --> 1S\n",
    "    a, b = point_test(0)\n",
    "    temp_test[a:b] = 1\n",
    "    \n",
    "    #SUB B --> 3\n",
    "    a, b = point_test(1)\n",
    "    temp_test[a:b] = 3\n",
    "    \n",
    "    #SUB C --> 5\n",
    "    a, b = point_test(2)\n",
    "    temp_test[a:b] = 5\n",
    "\n",
    "    #SUB D --> 1S\n",
    "    a, b = point_test(3)\n",
    "    temp_test[a:b] = 1\n",
    "\n",
    "    #SUB E --> 1F\n",
    "    a, b = point_test(4)\n",
    "    temp_test[a:b] = 2\n",
    "\n",
    "    #SUB F --> 10\n",
    "    a, b = point_test(5)\n",
    "    temp_test[a:b] = 10\n",
    "    \n",
    "    #SUB G --> 5\n",
    "    a, b = point_test(6)\n",
    "    temp_test[a:b] = 5\n",
    "\n",
    "    #SUB H --> 10\n",
    "    a, b = point_test(7)\n",
    "    temp_test[a:b] = 10\n",
    "    \n",
    "    #SUB I --> 1S\n",
    "    a, b = point_test(8)\n",
    "    temp_test[a:b] = 1\n",
    "\n",
    "    #SUB J --> 3\n",
    "    a, b = point_test(9)\n",
    "    temp_test[a:b] = 3\n",
    "    \n",
    "    #BATCHES 3/4 --> 1S\n",
    "    a, b = 1000000, 2000000\n",
    "    temp_test[a:b] = 1\n",
    "    \n",
    "    _label_train, _label_test = temp_train, temp_test\n",
    "    \n",
    "    l_mean, l_std = _label_train.mean(axis = 0), _label_train.std(axis = 0)\n",
    "\n",
    "    _label_train, _label_test = (_label_train-l_mean)/l_std, (_label_test-l_mean)/l_std   \n",
    "\n",
    "    _label_train, _label_test = _label_train.reshape(-1, LEN_, 1), _label_test.reshape(-1, LEN_, 1)\n",
    "    return _label_train, _label_test\n",
    "\n",
    "def roller(train, test, period = [15, 25, 50]):\n",
    "  train['group'] = train['time'].apply(lambda x: np.ceil(x*10000/500000))\n",
    "  test['group'] = test['time'].apply(lambda x: np.ceil(x*10000/500000))\n",
    "\n",
    "  for num in period:\n",
    "    train[f'signal_{num}_mean'] = train[['group', 'signal']].groupby('group')['signal'].rolling(num, center = True).mean().reset_index(0,drop=True)\n",
    "    test[f'signal_{num}_mean'] = test[['group', 'signal']].groupby('group')['signal'].rolling(num, center = True).mean().reset_index(0,drop=True)\n",
    "  \n",
    "  name = [f'signal_{x}_mean' for x in period]\n",
    "\n",
    "  return(train, test, name)\n",
    "\n",
    "def df_process():\n",
    "\n",
    "    observation_covariance = .0015\n",
    "    \n",
    "    train_clean = pd.read_csv('/kaggle/input/data-without-drift/train_clean.csv')\n",
    "    test_clean = pd.read_csv('/kaggle/input/data-without-drift/test_clean.csv')\n",
    "\n",
    "    #add cluster\n",
    "    _label_train, _label_test = segmenter(train_clean.shape, test_clean.shape)\n",
    "\n",
    "    #add rolling mean\n",
    "    train_clean, test_clean, name = roller(train_clean, test_clean)\n",
    "\n",
    "    print('Notch Filter...\\n')\n",
    "    b, a = signal.iirnotch(f0, Q, fs)\n",
    "\n",
    "    train_clean['signalQ'] = signal.filtfilt(b, a, train_clean.signal)\n",
    "    test_clean['signalQ'] = signal.filtfilt(b, a, test_clean.signal)\n",
    "\n",
    "    print('Kalman-train estimate...\\n')\n",
    "    pred_state, _ = Kalman1D(train_clean.signal.values, observation_covariance)\n",
    "    \n",
    "    train_clean['signal_kalman'] = pred_state\n",
    "\n",
    "    print('Kalman-test estimate...\\n')\n",
    "    pred_state, _ = Kalman1D(test_clean.signal.values, observation_covariance)\n",
    "\n",
    "    test_clean['signal_kalman'] = pred_state\n",
    "\n",
    "    n_classes = train_clean.open_channels.unique().shape[0]\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    train_clean['signal2'] = train_clean.signal**2\n",
    "    test_clean['signal2'] = test_clean.signal**2\n",
    "\n",
    "    new_feat = ['signal_kalman', 'signalQ', 'signal', 'signal2'] + name\n",
    "\n",
    "    train_mean = train_clean[new_feat].mean(axis = 0)\n",
    "    train_sigma = train_clean[new_feat].std(axis = 0)\n",
    "\n",
    "    train_clean[new_feat] = (train_clean[new_feat] - train_mean)/train_sigma\n",
    "    test_clean[new_feat] = (test_clean[new_feat] - train_mean)/train_sigma\n",
    "\n",
    "    train_clean[new_feat] = train_clean[new_feat].fillna(0)\n",
    "    test_clean[new_feat] = test_clean[new_feat].fillna(0)\n",
    "\n",
    "    train_signal = train_clean[new_feat].values.reshape(-1, LEN_, len(new_feat))\n",
    "    train_signal = np.concatenate((train_signal, _label_train), axis = 2)\n",
    "    \n",
    "    test_signal = test_clean[new_feat].values.reshape(-1, LEN_, len(new_feat))\n",
    "    test_signal = np.concatenate((test_signal, _label_test), axis = 2)\n",
    "\n",
    "    train_target = pd.get_dummies(train_clean['open_channels']).values.reshape(-1, LEN_, n_classes)\n",
    "    \n",
    "    group = np.tile(np.repeat(np.array(range(5)), 25), 10)\n",
    "\n",
    "    return(train_signal, train_target, test_signal, group)\n",
    "\n",
    "train_signal, train_target, test_signal, group = df_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_signal.npy\", train_signal, allow_pickle = True)\n",
    "np.save(\"train_target.npy\", train_target, allow_pickle = True)\n",
    "np.save(\"test_signal.npy\", test_signal, allow_pickle = True)\n",
    "np.save(\"group.npy\", group, allow_pickle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
