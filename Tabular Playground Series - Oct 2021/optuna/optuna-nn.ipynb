{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport os\nimport gc\nimport seaborn as sns\nfrom typing import List, Optional\nimport torch\nfrom optuna.integration import PyTorchLightningPruningCallback\nimport pytorch_lightning as pl\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport torch.nn.functional as F\nfrom torchmetrics import AUROC\n\nfrom utilities import (\n    RANDOM_STATE, TARGET_COL, N_FOLD, FOLD_STRAT_NAME,\n    EPOCHS, BATCH_SIZE, LEARNING_RATE, WEIGHT_DECAY, \n    EARLY_STOPPING_STEPS, EARLY_STOP\n)\n\nfrom nn_utilities import (\n    seed_everything, TabularDataset, InferenceDataset, run_training, inference_fn, Model_ff\n)\n\nDEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n\nINPUT_PATH = '../input/tabular-playground-series-oct-2021'\nPATH_NOTEBOOK = '../input/preprocess-gpu'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":2.023506,"end_time":"2021-10-13T14:42:51.751349","exception":false,"start_time":"2021-10-13T14:42:49.727843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T17:20:30.275973Z","iopub.execute_input":"2021-10-14T17:20:30.276501Z","iopub.status.idle":"2021-10-14T17:20:37.861209Z","shell.execute_reply.started":"2021-10-14T17:20:30.276424Z","shell.execute_reply":"2021-10-14T17:20:37.860315Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_pickle(os.path.join(PATH_NOTEBOOK, 'train_scaled.pkl'))","metadata":{"papermill":{"duration":11.101899,"end_time":"2021-10-13T14:43:02.863247","exception":false,"start_time":"2021-10-13T14:42:51.761348","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T17:20:37.863491Z","iopub.execute_input":"2021-10-14T17:20:37.863773Z","iopub.status.idle":"2021-10-14T17:20:49.802883Z","shell.execute_reply.started":"2021-10-14T17:20:37.863740Z","shell.execute_reply":"2021-10-14T17:20:49.802136Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(PATH_NOTEBOOK, 'feature_dic.pkl'), 'rb') as file:\n    feature_dic = pickle.load(file)","metadata":{"papermill":{"duration":0.023244,"end_time":"2021-10-13T14:43:02.896053","exception":false,"start_time":"2021-10-13T14:43:02.872809","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T17:20:49.803998Z","iopub.execute_input":"2021-10-14T17:20:49.804793Z","iopub.status.idle":"2021-10-14T17:20:49.816657Z","shell.execute_reply.started":"2021-10-14T17:20:49.804762Z","shell.execute_reply":"2021-10-14T17:20:49.816002Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#CONSTANT\nFEATURE = feature_dic['feature']\nCAT_COL = feature_dic['categorical']\nNUMERIC_COL = feature_dic['numerical']\n\nFOLD_LIST = list(range(N_FOLD))\n\ngc.collect()","metadata":{"papermill":{"duration":0.139745,"end_time":"2021-10-13T14:43:03.045659","exception":false,"start_time":"2021-10-13T14:43:02.905914","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-14T17:24:56.017662Z","iopub.execute_input":"2021-10-14T17:24:56.018536Z","iopub.status.idle":"2021-10-14T17:24:56.154872Z","shell.execute_reply.started":"2021-10-14T17:24:56.018491Z","shell.execute_reply":"2021-10-14T17:24:56.154013Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"70"},"metadata":{}}]},{"cell_type":"code","source":"class TabularDataset:\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n\n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        item = [\n            torch.tensor(self.features[idx, :], dtype=torch.float),\n            torch.tensor(self.targets[idx], dtype=torch.float)\n        ]\n        return item","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:24:56.321756Z","iopub.execute_input":"2021-10-14T17:24:56.321972Z","iopub.status.idle":"2021-10-14T17:24:56.327381Z","shell.execute_reply.started":"2021-10-14T17:24:56.321948Z","shell.execute_reply":"2021-10-14T17:24:56.326774Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n    def __init__(self, batch_size: int):\n        super().__init__()\n        self.batch_size = batch_size\n\n    def train_dataloader(self) -> DataLoader:\n        return DataLoader(\n            train_dataset, batch_size=self.batch_size, shuffle=True, pin_memory=True,\n            num_workers=os.cpu_count(), drop_last=True,\n        )\n    \n    def val_dataloader(self) -> DataLoader:\n        return DataLoader(\n            valid_dataset, batch_size=self.batch_size, shuffle=False, pin_memory=True,\n            num_workers=os.cpu_count(), drop_last=False,\n        )","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:24:56.755558Z","iopub.execute_input":"2021-10-14T17:24:56.756043Z","iopub.status.idle":"2021-10-14T17:24:56.761811Z","shell.execute_reply.started":"2021-10-14T17:24:56.756015Z","shell.execute_reply":"2021-10-14T17:24:56.761119Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def objective(trial: optuna.trial.Trial) -> float:\n    max_epochs = 100\n    steps_per_epoch = int(len(train_dataset)/max_epochs)\n\n    # We optimize the number of layers, hidden units in each layer and dropouts.\n    n_layers = trial.suggest_int(\"n_layers\", 1, 6)\n    dropout_list = [\n        trial.suggest_float(\"dropout_{}\".format(i), 0, 0.5) for i in range(n_layers)\n    ]\n    output_dims = [\n        trial.suggest_int(\"n_units_l{}\".format(i), 4, 1200, log=True) for i in range(n_layers)\n    ]\n\n    lr = trial.suggest_float(\"lr\", 1e-6, 1e-3)\n    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2)\n    \n    datamodule = DataModule(batch_size = BATCH_SIZE)\n    model = LightningNet(output_dims, dropout_list, lr, weight_decay, num_features = len(FEATURE),\n                         epoch = max_epochs, steps_per_epoch = steps_per_epoch)\n    \n    early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_auc\", patience = 5, verbose=False, mode=\"max\")\n    pruning_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_auc\")\n    \n    trainer = pl.Trainer(\n        logger=True,\n        checkpoint_callback=False,\n        max_epochs=max_epochs,\n        gpus=1 if torch.cuda.is_available() else None,\n        progress_bar_refresh_rate=0,\n        callbacks=[early_stop_callback, pruning_callback],\n    )\n    hyperparameters = dict(n_layers=n_layers, dropout_list=dropout_list, output_dims=output_dims, \n                           lr = lr, weight_decay = weight_decay)\n    \n    trainer.logger.log_hyperparams(hyperparameters)\n    trainer.fit(model, datamodule=datamodule)\n    \n    return trainer.callback_metrics[\"val_auc\"].item()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:38:00.053917Z","iopub.execute_input":"2021-10-14T17:38:00.054740Z","iopub.status.idle":"2021-10-14T17:38:00.072569Z","shell.execute_reply.started":"2021-10-14T17:38:00.054693Z","shell.execute_reply":"2021-10-14T17:38:00.071751Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, output_dims: List[int], dropout_list: List[float], num_features):\n        super().__init__()\n        \n        layers: List[nn.Module] = []\n\n        input_dim: int = num_features\n        for i, output_dim in enumerate(output_dims):\n            layers.append(nn.BatchNorm1d(input_dim))\n            layers.append(nn.Linear(input_dim, output_dim))\n            layers.append(nn.GELU())\n            layers.append(nn.Dropout(dropout_list[i]))\n            input_dim = output_dim\n        \n        layers.append(nn.BatchNorm1d(input_dim))\n        layers.append(nn.Linear(input_dim, 1))\n    \n        self.layers: nn.Module = nn.Sequential(*layers)\n    def forward(self, data: torch.Tensor) -> torch.Tensor:\n        logits = self.layers(data).squeeze(1)\n        return logits\n    \n    \nclass LightningNet(pl.LightningModule):\n    def __init__(self, output_dims: List[int], dropout_list: List[float], lr, weight_decay, num_features,\n                epoch, steps_per_epoch):\n        super().__init__()\n        self.model = Model(output_dims = output_dims, dropout_list = dropout_list, num_features = num_features)\n        self.lr = lr\n        self.weight_decay = weight_decay\n        self.steps_per_epoch = steps_per_epoch\n        self.epoch = epoch\n        self.auc_metric = AUROC(pos_label = 1)\n\n    def step(self, batch):\n        # return batch loss\n        data, target  = batch\n        pred = self(data)\n        loss  = F.binary_cross_entropy_with_logits(pred, target)\n        return loss, target, pred.sigmoid()\n\n    def forward(self, data: torch.Tensor) -> torch.Tensor:\n        return self.model(data)\n\n    def training_step(self, batch, batch_idx: int) -> torch.Tensor:\n        \n        loss, target, prob_pred = self.step(batch)\n        auc = self.auc_metric(preds = prob_pred, target = target.long())\n        tensorboard_logs = {'train_loss': loss, 'auc': auc}\n        \n        return {'loss': loss, 'auc': auc, 'log': tensorboard_logs}\n    \n    def validation_step(self, batch, batch_idx: int) -> None:\n        loss, target, prob_pred = self.step(batch)\n        return {'val_loss': loss, 'target': target.detach(), 'prob_pred': prob_pred.detach()}\n\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        target = torch.cat([x['target'] for x in outputs])\n        prob_pred = torch.cat([x['prob_pred'] for x in outputs])\n        \n        auc = self.auc_metric(preds = prob_pred, target = target.long())\n        tensorboard_logs = {'val_loss': avg_loss, 'val_auc': auc}\n        return {\n            'avg_val_loss': avg_loss, 'val_auc': auc, 'log': tensorboard_logs\n        }\n    \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr = self.lr, weight_decay = self.weight_decay)\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            max_lr=1e-2,\n            steps_per_epoch=self.steps_per_epoch,\n            epochs=self.epoch,\n            optimizer=optimizer,\n        )\n        return [optimizer], [scheduler]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:26:23.341357Z","iopub.execute_input":"2021-10-14T17:26:23.341622Z","iopub.status.idle":"2021-10-14T17:26:23.363957Z","shell.execute_reply.started":"2021-10-14T17:26:23.341591Z","shell.execute_reply":"2021-10-14T17:26:23.363139Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, output_dims: List[int], dropout_list: List[float], num_features):\n        super().__init__()\n        \n        layers: List[nn.Module] = []\n\n        input_dim: int = num_features\n        for i, output_dim in enumerate(output_dims):\n            layers.append(nn.BatchNorm1d(input_dim))\n            layers.append(nn.Linear(input_dim, output_dim))\n            layers.append(nn.GELU())\n            layers.append(nn.Dropout(dropout_list[i]))\n            input_dim = output_dim\n        \n        layers.append(nn.BatchNorm1d(input_dim))\n        layers.append(nn.Linear(input_dim, 1))\n    \n        self.layers: nn.Module = nn.Sequential(*layers)\n    def forward(self, data: torch.Tensor) -> torch.Tensor:\n        logits = self.layers(data).squeeze(1)\n        return logits\n    \n    \nclass LightningNet(pl.LightningModule):\n    def __init__(self, output_dims: List[int], dropout_list: List[float], lr, weight_decay, num_features,\n                epoch, steps_per_epoch):\n        super().__init__()\n        self.model = Model(output_dims = output_dims, dropout_list = dropout_list, num_features = num_features)\n        self.lr = lr\n        self.weight_decay = weight_decay\n        self.steps_per_epoch = steps_per_epoch\n        self.epoch = epoch\n        self.auc_metric = AUROC(pos_label = 1)\n\n    def step(self, batch):\n        # return batch loss\n        data, target  = batch\n        pred = self(data)\n        loss  = F.binary_cross_entropy_with_logits(pred, target)\n        return loss, target, pred.sigmoid()\n\n    def forward(self, data: torch.Tensor) -> torch.Tensor:\n        return self.model(data)\n\n    def training_step(self, batch, batch_idx: int) -> torch.Tensor:\n        loss, _, _ = self.step(batch)\n        return loss\n\n    def validation_step(self, batch, batch_idx: int) -> None:\n        loss, target, pred_prob = self.step(batch)\n        auc = self.auc_metric(pred_prob, target.long())\n        self.log(\"val_auc\", auc)\n        self.log(\"hp_metric\", auc, on_step=False, on_epoch=True)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr = self.lr, weight_decay = self.weight_decay)\n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            max_lr=1e-2,\n            steps_per_epoch=self.steps_per_epoch,\n            epochs=self.epoch,\n            optimizer=optimizer,\n        )\n        return [optimizer], [scheduler]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:38:01.658465Z","iopub.execute_input":"2021-10-14T17:38:01.658914Z","iopub.status.idle":"2021-10-14T17:38:01.677622Z","shell.execute_reply.started":"2021-10-14T17:38:01.658878Z","shell.execute_reply":"2021-10-14T17:38:01.676642Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#train test split for optuna-study\ntrain_x, test_x, train_y, test_y = train_test_split(\n    train[FEATURE], train[TARGET_COL], random_state = RANDOM_STATE, \n    stratify = train[TARGET_COL], test_size = .75\n)\n\n\ntrain_dataset = TabularDataset(train_x.values, train_y.values)\nvalid_dataset = TabularDataset(test_x.values, test_y.values)\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:38:03.016833Z","iopub.execute_input":"2021-10-14T17:38:03.017530Z","iopub.status.idle":"2021-10-14T17:38:05.920295Z","shell.execute_reply.started":"2021-10-14T17:38:03.017493Z","shell.execute_reply":"2021-10-14T17:38:05.919603Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"751"},"metadata":{}}]},{"cell_type":"code","source":"pruner = optuna.pruners.MedianPruner()\n\nstudy = optuna.create_study(direction=\"maximize\", pruner=pruner)\nstudy.optimize(objective, timeout=30500, show_progress_bar = True)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T17:38:06.232940Z","iopub.execute_input":"2021-10-14T17:38:06.233583Z","iopub.status.idle":"2021-10-14T17:43:04.222000Z","shell.execute_reply.started":"2021-10-14T17:38:06.233545Z","shell.execute_reply":"2021-10-14T17:43:04.220635Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2021-10-14 17:38:06,235]\u001b[0m A new study created in memory with name: no-name-a15bb043-4871-4b27-b2c7-8ce2a3c973f6\u001b[0m\n/opt/conda/lib/python3.7/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n  self._init_valid()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc55505db3e4977a50e80d6bac146b1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n  warnings.warn(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/optuna/trial/_trial.py:592: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n  step\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[I 2021-10-14 17:42:53,538]\u001b[0m Trial 0 finished with value: 0.8408616781234741 and parameters: {'n_layers': 2, 'dropout_0': 0.43849223366952667, 'dropout_1': 0.3001934981760253, 'n_units_l0': 9, 'n_units_l1': 28, 'lr': 0.0004553089117116581, 'weight_decay': 0.0028698355585040853}. Best is trial 0 with value: 0.8408616781234741.\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n  warnings.warn(*args, **kwargs)\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1047: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n","output_type":"stream"},{"name":"stdout","text":"\u001b[33m[W 2021-10-14 17:43:04,152]\u001b[0m Trial 1 failed because of the following error: KeyError('val_auc')\u001b[0m\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_40/691249158.py\", line 38, in objective\n    return trainer.callback_metrics[\"val_auc\"].item()\nKeyError: 'val_auc'\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_40/141306966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_40/691249158.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_auc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyError\u001b[0m: 'val_auc'"],"ename":"KeyError","evalue":"'val_auc'","output_type":"error"}]},{"cell_type":"code","source":"best_score = study.best_trial.values\nprint(best_score)","metadata":{"execution":{"iopub.execute_input":"2021-10-13T21:43:51.59383Z","iopub.status.busy":"2021-10-13T21:43:51.592864Z","iopub.status.idle":"2021-10-13T21:43:51.596013Z","shell.execute_reply":"2021-10-13T21:43:51.596498Z","shell.execute_reply.started":"2021-10-13T14:42:11.521846Z"},"papermill":{"duration":0.089668,"end_time":"2021-10-13T21:43:51.596684","exception":false,"start_time":"2021-10-13T21:43:51.507016","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_params = study.best_trial.params\nprint(final_params)","metadata":{"execution":{"iopub.execute_input":"2021-10-13T21:43:51.752459Z","iopub.status.busy":"2021-10-13T21:43:51.751549Z","iopub.status.idle":"2021-10-13T21:43:51.75466Z","shell.execute_reply":"2021-10-13T21:43:51.755165Z","shell.execute_reply.started":"2021-10-13T14:42:12.210053Z"},"papermill":{"duration":0.084173,"end_time":"2021-10-13T21:43:51.755335","exception":false,"start_time":"2021-10-13T21:43:51.671162","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"final_nn_param.pkl\", \"wb\") as file_name:\n    pickle.dump(final_params, file_name)\n","metadata":{"execution":{"iopub.execute_input":"2021-10-13T21:43:51.90979Z","iopub.status.busy":"2021-10-13T21:43:51.908828Z","iopub.status.idle":"2021-10-13T21:43:51.91424Z","shell.execute_reply":"2021-10-13T21:43:51.913703Z","shell.execute_reply.started":"2021-10-13T14:42:12.939803Z"},"papermill":{"duration":0.084111,"end_time":"2021-10-13T21:43:51.914377","exception":false,"start_time":"2021-10-13T21:43:51.830266","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}