{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from math import sin,log,pow,cos\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from scipy.sparse import csr_matrix,coo_matrix, hstack\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "\n",
    "import gc\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def choice(train,target,col,label,min_samples_leaf=20,smoothing=1,coo=True):\n",
    "    if label == 'one_hot':\n",
    "        X = one_hot_encoder(train,col)\n",
    "    if label == 'label':\n",
    "        X = label_encoder(train,col).reshape((-1,1))\n",
    "    if label == 'mean_target':\n",
    "        X = mean_target(train,target,col,min_samples_leaf,smoothing).reshape((-1,1))\n",
    "    if label == 'siner':\n",
    "        X = cyclical_siner_encoder(train,col).reshape((-1,1))\n",
    "    if label == 'coser':\n",
    "        X = cyclical_coser_encoder(train,col).reshape((-1,1))\n",
    "    if label == 'ordinal':\n",
    "        X =  ordinal_encoder(train,col).reshape((-1,1))\n",
    "    if coo:\n",
    "        return(csr_matrix(X))\n",
    "    else:\n",
    "        return(X)\n",
    "    \n",
    "def one_hot_encoder(train,col):\n",
    "    return(pd.get_dummies(train[col],prefix_sep='_',columns=col,drop_first=True))\n",
    "\n",
    "def label_encoder(train,col):\n",
    "    lbl_enc = LabelEncoder()\n",
    "    return(lbl_enc.fit_transform(train[col].values))\n",
    "\n",
    "def cyclical_coser_encoder(train,col):\n",
    "    period = train[col].max()\n",
    "    return((train[col].astype(float)).transform(coser,period=period).values)\n",
    "\n",
    "def cyclical_siner_encoder(train,col):\n",
    "    period = train[col].max()\n",
    "    return((train[col].astype(float)).transform(coser,period=period).values)\n",
    "\n",
    "def ordinal_encoder(train,col):\n",
    "    if col == 'ord_0':\n",
    "        return(order0)\n",
    "    if col=='ord_1':\n",
    "        return(order1)\n",
    "    if col=='ord_2':\n",
    "        return(order2)\n",
    "    if col=='ord_3':\n",
    "        return(order3)\n",
    "    if col=='ord_4':\n",
    "        return(order4)\n",
    "    if col=='ord_5':\n",
    "        return(order5)\n",
    "\n",
    "def mean_target(train,target,col,min_samples_leaf,smoothing):\n",
    "        vector = np.zeros(len(train[col]))\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        for trn_idx, val_idx in folds.split(train.values, target.values):\n",
    "            trn_f, trn_tgt = train[col].iloc[trn_idx], target.iloc[trn_idx]\n",
    "            val_f, val_tgt = train[col].iloc[val_idx], target.iloc[val_idx]\n",
    "            trn_tf, val_tf = target_encode(trn_series=trn_f, \n",
    "                                             tst_series=val_f, \n",
    "                                             target=trn_tgt, \n",
    "                                             min_samples_leaf=min_samples_leaf , \n",
    "                                             smoothing=smoothing ,\n",
    "                                             noise_level=0)\n",
    "            vector[val_idx]=val_tf\n",
    "        return(vector)\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in tqdm_notebook(df.columns):\n",
    "        gc.collect()\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def siner(x,period):\n",
    "    return(sin(2*np.pi*x/period))\n",
    "def coser(x,period):\n",
    "    return(cos(2*np.pi*x/period))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "bin_0        one_hot\n",
       "bin_1        one_hot\n",
       "bin_2        one_hot\n",
       "bin_3        one_hot\n",
       "bin_4    mean_target\n",
       "nom_0        one_hot\n",
       "nom_1        one_hot\n",
       "nom_2    mean_target\n",
       "nom_3        one_hot\n",
       "nom_4        one_hot\n",
       "nom_5        one_hot\n",
       "nom_6        one_hot\n",
       "nom_7        one_hot\n",
       "nom_8    mean_target\n",
       "nom_9    mean_target\n",
       "ord_0        one_hot\n",
       "ord_1    mean_target\n",
       "ord_2        one_hot\n",
       "ord_3        one_hot\n",
       "ord_4        one_hot\n",
       "ord_5    mean_target\n",
       "day          one_hot\n",
       "month        one_hot\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoding = pd.read_csv('../input/transformer-selector-ord/results.csv',header=None,index_col=0)\n",
    "\n",
    "Encoding = pd.Series(Encoding.values.flatten(),index=Encoding.index,dtype='str')\n",
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/cat-in-the-dat/'\n",
    "\n",
    "train = pd.read_csv(f'{path}train.csv')\n",
    "test = pd.read_csv(f'{path}test.csv')\n",
    "\n",
    "#find test column with unseen values \n",
    "difference_set = [len(set(test[col].values) - set(train[col].values)) for col in test.columns]\n",
    "difference_set = test.columns[[x>0 and x<1000 for x in difference_set]].tolist()\n",
    "\n",
    "#create dictionary with value of unseen data\n",
    "difference_values = {col: {'value': set(test[col].values) - set(train[col].values)} for col in difference_set}\n",
    "\n",
    "#replace it with most frequent value in training set\n",
    "for col in difference_values:\n",
    "    test.loc[test[col].isin(difference_values[col]['value']),col]=train[col].value_counts().idxmax()\n",
    "\n",
    "drop_col = ['id','target']\n",
    "target=train['target']\n",
    "\n",
    "train = train.drop(drop_col, axis=1)\n",
    "test = test.drop(['id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in range(Encoding.shape[0]):\n",
    "    gc.collect()\n",
    "    col = Encoding.index[N]\n",
    "    label = Encoding[N]\n",
    "    if N == 0:\n",
    "        Matrix = choice(train = train,target = target,col = col,label = label,coo=True)\n",
    "    else:\n",
    "        Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,coo=True)],format='csr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0  ; AUC : 0.8009616846460874\n",
      "Fold : 1  ; AUC : 0.80137588250105\n",
      "Fold : 2  ; AUC : 0.8029649819266538\n",
      "Fold : 3  ; AUC : 0.8020879226105712\n",
      "Fold : 4  ; AUC : 0.8000017006283286\n",
      "Initial AUC : 0.8014784344625383\n"
     ]
    }
   ],
   "source": [
    "param={'C':.1,'max_iter':10000,'solver':'lbfgs','n_jobs':4}\n",
    "score=0\n",
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True,random_state=0)\n",
    "for fold_ ,(trn_idx, val_idx) in enumerate(folds.split(Matrix, target)):\n",
    "        train_x, train_y = Matrix[trn_idx,:], target[trn_idx]\n",
    "        valid_x, valid_y = Matrix[val_idx,:], target[val_idx]\n",
    "        model = LogisticRegression(**param, random_state=0)\n",
    "        model.fit(train_x, train_y)\n",
    "        score_temp = roc_auc_score(valid_y,model.predict_proba(valid_x)[:,1])\n",
    "        print('Fold : {}  ; AUC : {}'.format(fold_,score_temp))\n",
    "        score += score_temp/n_fold\n",
    "print('Initial AUC : {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_bayes(\n",
    "    C,\n",
    "    min_bin_4,\n",
    "    smoot_bin_4,\n",
    "    min_nom_2,\n",
    "    smoot_nom_2,\n",
    "    min_nom_8,\n",
    "    smoot_nom_8,\n",
    "    min_nom_9,\n",
    "    smoot_nom_9,\n",
    "    min_ord_1,\n",
    "    smoot_ord_1,\n",
    "    min_ord_5,\n",
    "    smoot_ord_5):\n",
    "    \n",
    "    min_bin_4 = int(min_bin_4)\n",
    "    smoot_bin_4 = int(smoot_bin_4)\n",
    "    \n",
    "    min_nom_2 = int(min_nom_2)\n",
    "    smoot_nom_2 = int(smoot_nom_2)\n",
    "    \n",
    "    min_nom_9 = int(min_nom_9)\n",
    "    smoot_nom_9 = int(smoot_nom_9)\n",
    "\n",
    "    min_ord_1 = int(min_ord_1)\n",
    "    smoot_ord_1 = int(smoot_ord_1)\n",
    "\n",
    "    min_ord_5 = int(min_ord_5)\n",
    "    smoot_ord_5 = int(smoot_ord_5)\n",
    "\n",
    "\n",
    "    for N in range(Encoding.shape[0]):\n",
    "        gc.collect()\n",
    "        col = Encoding.index[N]\n",
    "        label = Encoding[N]\n",
    "        if N == 0:\n",
    "            Matrix = choice(train = train,target = target,col = col,label = label,coo=True)\n",
    "        else:\n",
    "            if label == 'bin_4':\n",
    "                Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,min_samples_leaf=min_bin_4,smoothing=smoot_bin_4,coo=True)],format='csr')\n",
    "            if label == 'nom_2':\n",
    "                Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,min_samples_leaf=min_nom_2,smoothing=smoot_nom_2,coo=True)],format='csr')\n",
    "            if label == 'nom_9':\n",
    "                Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,min_samples_leaf=min_nom_9,smoothing=smoot_nom_9,coo=True)],format='csr')\n",
    "            if label == 'ord_1':\n",
    "                Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,min_samples_leaf=min_ord_1,smoothing=smoot_ord_1,coo=True)],format='csr')\n",
    "            if label == 'ord_5':\n",
    "                Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,min_samples_leaf=min_ord_5,smoothing=smoot_ord_5,coo=True)],format='csr')\n",
    "            if label not in ['bin_4','nom_2','nom_9','ord_1','ord_5']:\n",
    "                Matrix = hstack([Matrix,choice(train = train,target = target,col = col,label = label,coo=True)],format='csr')\n",
    "                \n",
    "    param={'C':C,'max_iter':10000,'solver':'lbfgs','n_jobs':4}\n",
    "    score=0\n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True,random_state=0)\n",
    "    for trn_idx, val_idx in folds.split(Matrix, target):\n",
    "            train_x, train_y = Matrix[trn_idx,:], target[trn_idx]\n",
    "            valid_x, valid_y = Matrix[val_idx,:], target[val_idx]\n",
    "            model = LogisticRegression(**param, random_state=0)\n",
    "            model.fit(train_x, train_y)\n",
    "            score += roc_auc_score(valid_y,model.predict_proba(valid_x)[:,1])/n_fold\n",
    "    return(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   |     C     | min_bin_4 | min_nom_2 | min_nom_8 | min_nom_9 | min_ord_1 | min_ord_5 | smoot_... | smoot_... | smoot_... | smoot_... | smoot_... | smoot_... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.4193  \u001b[0m | \u001b[0m 720.6   \u001b[0m | \u001b[0m 1.114   \u001b[0m | \u001b[0m 303.0   \u001b[0m | \u001b[0m 147.6   \u001b[0m | \u001b[0m 93.25   \u001b[0m | \u001b[0m 187.1   \u001b[0m | \u001b[0m 346.2   \u001b[0m | \u001b[0m 397.4   \u001b[0m | \u001b[0m 539.3   \u001b[0m | \u001b[0m 419.8   \u001b[0m | \u001b[0m 685.5   \u001b[0m | \u001b[0m 205.2   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8786  \u001b[0m | \u001b[0m 28.36   \u001b[0m | \u001b[0m 670.8   \u001b[0m | \u001b[0m 417.9   \u001b[0m | \u001b[0m 559.1   \u001b[0m | \u001b[0m 141.2   \u001b[0m | \u001b[0m 198.9   \u001b[0m | \u001b[0m 800.9   \u001b[0m | \u001b[0m 968.3   \u001b[0m | \u001b[0m 314.1   \u001b[0m | \u001b[0m 692.6   \u001b[0m | \u001b[0m 876.5   \u001b[0m | \u001b[0m 894.7   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.08862 \u001b[0m | \u001b[0m 40.02   \u001b[0m | \u001b[0m 170.7   \u001b[0m | \u001b[0m 878.3   \u001b[0m | \u001b[0m 99.25   \u001b[0m | \u001b[0m 421.7   \u001b[0m | \u001b[0m 957.9   \u001b[0m | \u001b[0m 533.6   \u001b[0m | \u001b[0m 692.2   \u001b[0m | \u001b[0m 316.2   \u001b[0m | \u001b[0m 686.8   \u001b[0m | \u001b[0m 834.8   \u001b[0m | \u001b[0m 19.27   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7511  \u001b[0m | \u001b[0m 988.9   \u001b[0m | \u001b[0m 748.4   \u001b[0m | \u001b[0m 281.2   \u001b[0m | \u001b[0m 789.5   \u001b[0m | \u001b[0m 104.1   \u001b[0m | \u001b[0m 448.4   \u001b[0m | \u001b[0m 908.7   \u001b[0m | \u001b[0m 294.3   \u001b[0m | \u001b[0m 288.5   \u001b[0m | \u001b[0m 130.9   \u001b[0m | \u001b[0m 20.35   \u001b[0m | \u001b[0m 679.2   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8016  \u001b[0m | \u001b[95m 0.2147  \u001b[0m | \u001b[95m 266.3   \u001b[0m | \u001b[95m 492.1   \u001b[0m | \u001b[95m 54.31   \u001b[0m | \u001b[95m 574.5   \u001b[0m | \u001b[95m 147.6   \u001b[0m | \u001b[95m 589.7   \u001b[0m | \u001b[95m 700.1   \u001b[0m | \u001b[95m 103.2   \u001b[0m | \u001b[95m 414.6   \u001b[0m | \u001b[95m 694.7   \u001b[0m | \u001b[95m 414.8   \u001b[0m | \u001b[95m 50.9    \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8509  \u001b[0m | \u001b[0m 185.5   \u001b[0m | \u001b[0m 453.1   \u001b[0m | \u001b[0m 198.0   \u001b[0m | \u001b[0m 583.0   \u001b[0m | \u001b[0m 560.7   \u001b[0m | \u001b[0m 436.2   \u001b[0m | \u001b[0m 258.8   \u001b[0m | \u001b[0m 80.04   \u001b[0m | \u001b[0m 774.1   \u001b[0m | \u001b[0m 312.7   \u001b[0m | \u001b[0m 942.7   \u001b[0m | \u001b[0m 146.8   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.4735  \u001b[0m | \u001b[0m 276.2   \u001b[0m | \u001b[0m 701.0   \u001b[0m | \u001b[0m 778.9   \u001b[0m | \u001b[0m 848.7   \u001b[0m | \u001b[0m 540.0   \u001b[0m | \u001b[0m 713.1   \u001b[0m | \u001b[0m 974.5   \u001b[0m | \u001b[0m 406.5   \u001b[0m | \u001b[0m 431.0   \u001b[0m | \u001b[0m 144.9   \u001b[0m | \u001b[0m 163.8   \u001b[0m | \u001b[0m 386.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 673.5   \u001b[0m | \u001b[0m 216.5   \u001b[0m | \u001b[0m 26.83   \u001b[0m | \u001b[0m 743.7   \u001b[0m | \u001b[0m 972.8   \u001b[0m | \u001b[0m 709.5   \u001b[0m | \u001b[0m 149.4   \u001b[0m | \u001b[0m 855.6   \u001b[0m | \u001b[0m 985.5   \u001b[0m | \u001b[0m 791.8   \u001b[0m | \u001b[0m 33.15   \u001b[0m | \u001b[0m 959.3   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.03763 \u001b[0m | \u001b[0m 813.7   \u001b[0m | \u001b[0m 985.7   \u001b[0m | \u001b[0m 981.5   \u001b[0m | \u001b[0m 145.5   \u001b[0m | \u001b[0m 823.0   \u001b[0m | \u001b[0m 251.9   \u001b[0m | \u001b[0m 67.81   \u001b[0m | \u001b[0m 356.9   \u001b[0m | \u001b[0m 48.05   \u001b[0m | \u001b[0m 722.5   \u001b[0m | \u001b[0m 195.1   \u001b[0m | \u001b[0m 154.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1279  \u001b[0m | \u001b[0m 861.1   \u001b[0m | \u001b[0m 742.8   \u001b[0m | \u001b[0m 941.4   \u001b[0m | \u001b[0m 62.88   \u001b[0m | \u001b[0m 194.1   \u001b[0m | \u001b[0m 11.48   \u001b[0m | \u001b[0m 911.5   \u001b[0m | \u001b[0m 51.94   \u001b[0m | \u001b[0m 987.2   \u001b[0m | \u001b[0m 672.0   \u001b[0m | \u001b[0m 783.8   \u001b[0m | \u001b[0m 934.9   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.2926  \u001b[0m | \u001b[0m 867.3   \u001b[0m | \u001b[0m 4.365   \u001b[0m | \u001b[0m 611.0   \u001b[0m | \u001b[0m 962.4   \u001b[0m | \u001b[0m 994.7   \u001b[0m | \u001b[0m 113.7   \u001b[0m | \u001b[0m 753.1   \u001b[0m | \u001b[0m 112.5   \u001b[0m | \u001b[0m 155.1   \u001b[0m | \u001b[0m 761.9   \u001b[0m | \u001b[0m 704.0   \u001b[0m | \u001b[0m 175.5   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 98.61   \u001b[0m | \u001b[0m 431.9   \u001b[0m | \u001b[0m 28.63   \u001b[0m | \u001b[0m 129.8   \u001b[0m | \u001b[0m 615.0   \u001b[0m | \u001b[0m 610.4   \u001b[0m | \u001b[0m 938.4   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 138.6   \u001b[0m | \u001b[0m 156.0   \u001b[0m | \u001b[0m 79.43   \u001b[0m | \u001b[0m 993.5   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.8016  \u001b[0m | \u001b[95m 0.2107  \u001b[0m | \u001b[95m 301.0   \u001b[0m | \u001b[95m 920.4   \u001b[0m | \u001b[95m 64.1    \u001b[0m | \u001b[95m 106.1   \u001b[0m | \u001b[95m 666.4   \u001b[0m | \u001b[95m 181.4   \u001b[0m | \u001b[95m 992.1   \u001b[0m | \u001b[95m 811.6   \u001b[0m | \u001b[95m 472.7   \u001b[0m | \u001b[95m 30.84   \u001b[0m | \u001b[95m 561.9   \u001b[0m | \u001b[95m 19.49   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2504  \u001b[0m | \u001b[0m 626.6   \u001b[0m | \u001b[0m 569.5   \u001b[0m | \u001b[0m 950.9   \u001b[0m | \u001b[0m 57.12   \u001b[0m | \u001b[0m 255.4   \u001b[0m | \u001b[0m 185.8   \u001b[0m | \u001b[0m 650.1   \u001b[0m | \u001b[0m 757.5   \u001b[0m | \u001b[0m 374.9   \u001b[0m | \u001b[0m 916.6   \u001b[0m | \u001b[0m 223.4   \u001b[0m | \u001b[0m 312.2   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 99.69   \u001b[0m | \u001b[0m 264.2   \u001b[0m | \u001b[0m 998.3   \u001b[0m | \u001b[0m 484.8   \u001b[0m | \u001b[0m 302.8   \u001b[0m | \u001b[0m 109.9   \u001b[0m | \u001b[0m 446.3   \u001b[0m | \u001b[0m 56.48   \u001b[0m | \u001b[0m 940.3   \u001b[0m | \u001b[0m 10.44   \u001b[0m | \u001b[0m 124.5   \u001b[0m | \u001b[0m 488.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2591  \u001b[0m | \u001b[0m 885.9   \u001b[0m | \u001b[0m 8.092   \u001b[0m | \u001b[0m 996.9   \u001b[0m | \u001b[0m 303.0   \u001b[0m | \u001b[0m 494.0   \u001b[0m | \u001b[0m 871.2   \u001b[0m | \u001b[0m 885.2   \u001b[0m | \u001b[0m 949.1   \u001b[0m | \u001b[0m 971.6   \u001b[0m | \u001b[0m 631.4   \u001b[0m | \u001b[0m 338.3   \u001b[0m | \u001b[0m 29.15   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.493   \u001b[0m | \u001b[0m 43.24   \u001b[0m | \u001b[0m 138.9   \u001b[0m | \u001b[0m 71.25   \u001b[0m | \u001b[0m 833.5   \u001b[0m | \u001b[0m 514.9   \u001b[0m | \u001b[0m 177.4   \u001b[0m | \u001b[0m 674.3   \u001b[0m | \u001b[0m 164.0   \u001b[0m | \u001b[0m 864.5   \u001b[0m | \u001b[0m 966.8   \u001b[0m | \u001b[0m 153.1   \u001b[0m | \u001b[0m 314.6   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3542  \u001b[0m | \u001b[0m 860.3   \u001b[0m | \u001b[0m 828.7   \u001b[0m | \u001b[0m 75.22   \u001b[0m | \u001b[0m 88.24   \u001b[0m | \u001b[0m 27.3    \u001b[0m | \u001b[0m 956.8   \u001b[0m | \u001b[0m 962.0   \u001b[0m | \u001b[0m 238.9   \u001b[0m | \u001b[0m 976.2   \u001b[0m | \u001b[0m 879.4   \u001b[0m | \u001b[0m 417.4   \u001b[0m | \u001b[0m 234.4   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.4312  \u001b[0m | \u001b[0m 839.6   \u001b[0m | \u001b[0m 544.3   \u001b[0m | \u001b[0m 785.1   \u001b[0m | \u001b[0m 686.0   \u001b[0m | \u001b[0m 243.1   \u001b[0m | \u001b[0m 519.9   \u001b[0m | \u001b[0m 906.4   \u001b[0m | \u001b[0m 272.3   \u001b[0m | \u001b[0m 579.7   \u001b[0m | \u001b[0m 921.0   \u001b[0m | \u001b[0m 906.0   \u001b[0m | \u001b[0m 339.1   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.2929  \u001b[0m | \u001b[0m 834.8   \u001b[0m | \u001b[0m 426.7   \u001b[0m | \u001b[0m 81.43   \u001b[0m | \u001b[0m 922.9   \u001b[0m | \u001b[0m 248.4   \u001b[0m | \u001b[0m 170.4   \u001b[0m | \u001b[0m 193.5   \u001b[0m | \u001b[0m 881.8   \u001b[0m | \u001b[0m 963.8   \u001b[0m | \u001b[0m 103.6   \u001b[0m | \u001b[0m 933.8   \u001b[0m | \u001b[0m 52.53   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.288   \u001b[0m | \u001b[0m 9.48    \u001b[0m | \u001b[0m 53.93   \u001b[0m | \u001b[0m 57.42   \u001b[0m | \u001b[0m 912.0   \u001b[0m | \u001b[0m 787.8   \u001b[0m | \u001b[0m 873.3   \u001b[0m | \u001b[0m 923.8   \u001b[0m | \u001b[0m 40.76   \u001b[0m | \u001b[0m 579.4   \u001b[0m | \u001b[0m 19.33   \u001b[0m | \u001b[0m 983.9   \u001b[0m | \u001b[0m 786.5   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.4733  \u001b[0m | \u001b[0m 691.5   \u001b[0m | \u001b[0m 235.8   \u001b[0m | \u001b[0m 23.2    \u001b[0m | \u001b[0m 1.826   \u001b[0m | \u001b[0m 960.6   \u001b[0m | \u001b[0m 29.08   \u001b[0m | \u001b[0m 767.5   \u001b[0m | \u001b[0m 914.6   \u001b[0m | \u001b[0m 992.3   \u001b[0m | \u001b[0m 275.2   \u001b[0m | \u001b[0m 556.6   \u001b[0m | \u001b[0m 789.7   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.6827  \u001b[0m | \u001b[0m 778.8   \u001b[0m | \u001b[0m 70.52   \u001b[0m | \u001b[0m 54.61   \u001b[0m | \u001b[0m 997.0   \u001b[0m | \u001b[0m 134.2   \u001b[0m | \u001b[0m 859.5   \u001b[0m | \u001b[0m 992.3   \u001b[0m | \u001b[0m 812.8   \u001b[0m | \u001b[0m 322.4   \u001b[0m | \u001b[0m 225.8   \u001b[0m | \u001b[0m 207.3   \u001b[0m | \u001b[0m 878.5   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.914   \u001b[0m | \u001b[0m 91.84   \u001b[0m | \u001b[0m 7.65    \u001b[0m | \u001b[0m 971.9   \u001b[0m | \u001b[0m 740.0   \u001b[0m | \u001b[0m 420.7   \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 939.1   \u001b[0m | \u001b[0m 952.1   \u001b[0m | \u001b[0m 975.0   \u001b[0m | \u001b[0m 934.3   \u001b[0m | \u001b[0m 701.0   \u001b[0m | \u001b[0m 94.82   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 644.0   \u001b[0m | \u001b[0m 908.7   \u001b[0m | \u001b[0m 961.4   \u001b[0m | \u001b[0m 980.2   \u001b[0m | \u001b[0m 137.5   \u001b[0m | \u001b[0m 758.1   \u001b[0m | \u001b[0m 6.383   \u001b[0m | \u001b[0m 915.3   \u001b[0m | \u001b[0m 771.0   \u001b[0m | \u001b[0m 78.99   \u001b[0m | \u001b[0m 594.1   \u001b[0m | \u001b[0m 934.0   \u001b[0m |\n",
      "| \u001b[95m 26      \u001b[0m | \u001b[95m 0.8016  \u001b[0m | \u001b[95m 0.1675  \u001b[0m | \u001b[95m 999.3   \u001b[0m | \u001b[95m 998.2   \u001b[0m | \u001b[95m 478.6   \u001b[0m | \u001b[95m 932.4   \u001b[0m | \u001b[95m 998.8   \u001b[0m | \u001b[95m 929.9   \u001b[0m | \u001b[95m 853.7   \u001b[0m | \u001b[95m 955.7   \u001b[0m | \u001b[95m 818.8   \u001b[0m | \u001b[95m 627.7   \u001b[0m | \u001b[95m 857.6   \u001b[0m | \u001b[95m 192.2   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.761   \u001b[0m | \u001b[0m 557.0   \u001b[0m | \u001b[0m 958.4   \u001b[0m | \u001b[0m 670.6   \u001b[0m | \u001b[0m 645.6   \u001b[0m | \u001b[0m 895.8   \u001b[0m | \u001b[0m 314.5   \u001b[0m | \u001b[0m 177.2   \u001b[0m | \u001b[0m 390.4   \u001b[0m | \u001b[0m 536.7   \u001b[0m | \u001b[0m 943.9   \u001b[0m | \u001b[0m 61.49   \u001b[0m | \u001b[0m 727.0   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8007  \u001b[0m | \u001b[0m 0.05067 \u001b[0m | \u001b[0m 7.308   \u001b[0m | \u001b[0m 244.7   \u001b[0m | \u001b[0m 942.6   \u001b[0m | \u001b[0m 22.14   \u001b[0m | \u001b[0m 13.54   \u001b[0m | \u001b[0m 974.1   \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 101.4   \u001b[0m | \u001b[0m 930.7   \u001b[0m | \u001b[0m 985.7   \u001b[0m | \u001b[0m 292.8   \u001b[0m | \u001b[0m 981.1   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.797   \u001b[0m | \u001b[0m 0.01852 \u001b[0m | \u001b[0m 989.6   \u001b[0m | \u001b[0m 390.3   \u001b[0m | \u001b[0m 213.6   \u001b[0m | \u001b[0m 758.1   \u001b[0m | \u001b[0m 692.9   \u001b[0m | \u001b[0m 657.8   \u001b[0m | \u001b[0m 745.5   \u001b[0m | \u001b[0m 845.2   \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 240.6   \u001b[0m | \u001b[0m 714.2   \u001b[0m | \u001b[0m 12.43   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.801   \u001b[0m | \u001b[0m 0.05892 \u001b[0m | \u001b[0m 430.0   \u001b[0m | \u001b[0m 75.06   \u001b[0m | \u001b[0m 288.4   \u001b[0m | \u001b[0m 535.3   \u001b[0m | \u001b[0m 898.1   \u001b[0m | \u001b[0m 369.6   \u001b[0m | \u001b[0m 920.3   \u001b[0m | \u001b[0m 70.55   \u001b[0m | \u001b[0m 703.4   \u001b[0m | \u001b[0m 206.1   \u001b[0m | \u001b[0m 796.3   \u001b[0m | \u001b[0m 854.8   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2388  \u001b[0m | \u001b[0m 23.91   \u001b[0m | \u001b[0m 959.7   \u001b[0m | \u001b[0m 726.1   \u001b[0m | \u001b[0m 991.1   \u001b[0m | \u001b[0m 794.9   \u001b[0m | \u001b[0m 489.7   \u001b[0m | \u001b[0m 889.4   \u001b[0m | \u001b[0m 257.1   \u001b[0m | \u001b[0m 954.4   \u001b[0m | \u001b[0m 902.9   \u001b[0m | \u001b[0m 132.7   \u001b[0m | \u001b[0m 619.3   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3042  \u001b[0m | \u001b[0m 248.6   \u001b[0m | \u001b[0m 957.0   \u001b[0m | \u001b[0m 160.6   \u001b[0m | \u001b[0m 774.4   \u001b[0m | \u001b[0m 334.5   \u001b[0m | \u001b[0m 81.18   \u001b[0m | \u001b[0m 922.7   \u001b[0m | \u001b[0m 595.7   \u001b[0m | \u001b[0m 978.1   \u001b[0m | \u001b[0m 781.0   \u001b[0m | \u001b[0m 929.8   \u001b[0m | \u001b[0m 961.1   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 0.9727  \u001b[0m | \u001b[0m 152.3   \u001b[0m | \u001b[0m 848.7   \u001b[0m | \u001b[0m 594.4   \u001b[0m | \u001b[0m 146.5   \u001b[0m | \u001b[0m 29.58   \u001b[0m | \u001b[0m 156.6   \u001b[0m | \u001b[0m 583.8   \u001b[0m | \u001b[0m 932.8   \u001b[0m | \u001b[0m 987.7   \u001b[0m | \u001b[0m 27.21   \u001b[0m | \u001b[0m 53.02   \u001b[0m | \u001b[0m 937.0   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 341.1   \u001b[0m | \u001b[0m 966.1   \u001b[0m | \u001b[0m 119.8   \u001b[0m | \u001b[0m 16.56   \u001b[0m | \u001b[0m 30.7    \u001b[0m | \u001b[0m 699.0   \u001b[0m | \u001b[0m 893.7   \u001b[0m | \u001b[0m 25.19   \u001b[0m | \u001b[0m 949.9   \u001b[0m | \u001b[0m 871.0   \u001b[0m | \u001b[0m 964.3   \u001b[0m | \u001b[0m 790.2   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2574  \u001b[0m | \u001b[0m 186.6   \u001b[0m | \u001b[0m 817.2   \u001b[0m | \u001b[0m 595.0   \u001b[0m | \u001b[0m 987.3   \u001b[0m | \u001b[0m 70.6    \u001b[0m | \u001b[0m 78.76   \u001b[0m | \u001b[0m 908.2   \u001b[0m | \u001b[0m 4.129   \u001b[0m | \u001b[0m 722.2   \u001b[0m | \u001b[0m 924.6   \u001b[0m | \u001b[0m 810.1   \u001b[0m | \u001b[0m 12.32   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1863  \u001b[0m | \u001b[0m 514.1   \u001b[0m | \u001b[0m 254.1   \u001b[0m | \u001b[0m 889.0   \u001b[0m | \u001b[0m 398.4   \u001b[0m | \u001b[0m 937.9   \u001b[0m | \u001b[0m 746.7   \u001b[0m | \u001b[0m 915.1   \u001b[0m | \u001b[0m 404.8   \u001b[0m | \u001b[0m 133.1   \u001b[0m | \u001b[0m 972.8   \u001b[0m | \u001b[0m 956.9   \u001b[0m | \u001b[0m 714.8   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2076  \u001b[0m | \u001b[0m 136.8   \u001b[0m | \u001b[0m 83.72   \u001b[0m | \u001b[0m 147.0   \u001b[0m | \u001b[0m 639.9   \u001b[0m | \u001b[0m 332.8   \u001b[0m | \u001b[0m 42.11   \u001b[0m | \u001b[0m 976.6   \u001b[0m | \u001b[0m 176.1   \u001b[0m | \u001b[0m 993.7   \u001b[0m | \u001b[0m 967.6   \u001b[0m | \u001b[0m 5.091   \u001b[0m | \u001b[0m 333.2   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.9581  \u001b[0m | \u001b[0m 203.2   \u001b[0m | \u001b[0m 981.9   \u001b[0m | \u001b[0m 895.7   \u001b[0m | \u001b[0m 118.1   \u001b[0m | \u001b[0m 897.3   \u001b[0m | \u001b[0m 260.8   \u001b[0m | \u001b[0m 872.5   \u001b[0m | \u001b[0m 466.9   \u001b[0m | \u001b[0m 967.8   \u001b[0m | \u001b[0m 10.82   \u001b[0m | \u001b[0m 889.4   \u001b[0m | \u001b[0m 719.4   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7353  \u001b[0m | \u001b[0m 368.7   \u001b[0m | \u001b[0m 429.2   \u001b[0m | \u001b[0m 905.1   \u001b[0m | \u001b[0m 954.5   \u001b[0m | \u001b[0m 32.39   \u001b[0m | \u001b[0m 185.1   \u001b[0m | \u001b[0m 978.9   \u001b[0m | \u001b[0m 27.72   \u001b[0m | \u001b[0m 969.4   \u001b[0m | \u001b[0m 190.5   \u001b[0m | \u001b[0m 222.4   \u001b[0m | \u001b[0m 295.9   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.9178  \u001b[0m | \u001b[0m 123.5   \u001b[0m | \u001b[0m 284.8   \u001b[0m | \u001b[0m 815.7   \u001b[0m | \u001b[0m 611.5   \u001b[0m | \u001b[0m 116.6   \u001b[0m | \u001b[0m 958.6   \u001b[0m | \u001b[0m 874.1   \u001b[0m | \u001b[0m 848.5   \u001b[0m | \u001b[0m 917.6   \u001b[0m | \u001b[0m 978.2   \u001b[0m | \u001b[0m 821.1   \u001b[0m | \u001b[0m 938.4   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.248   \u001b[0m | \u001b[0m 989.2   \u001b[0m | \u001b[0m 114.7   \u001b[0m | \u001b[0m 964.8   \u001b[0m | \u001b[0m 948.0   \u001b[0m | \u001b[0m 190.0   \u001b[0m | \u001b[0m 478.2   \u001b[0m | \u001b[0m 45.07   \u001b[0m | \u001b[0m 283.1   \u001b[0m | \u001b[0m 964.9   \u001b[0m | \u001b[0m 199.0   \u001b[0m | \u001b[0m 947.2   \u001b[0m | \u001b[0m 904.7   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.353   \u001b[0m | \u001b[0m 63.03   \u001b[0m | \u001b[0m 968.3   \u001b[0m | \u001b[0m 31.82   \u001b[0m | \u001b[0m 97.11   \u001b[0m | \u001b[0m 954.0   \u001b[0m | \u001b[0m 54.91   \u001b[0m | \u001b[0m 47.91   \u001b[0m | \u001b[0m 33.15   \u001b[0m | \u001b[0m 832.0   \u001b[0m | \u001b[0m 628.7   \u001b[0m | \u001b[0m 151.9   \u001b[0m | \u001b[0m 33.42   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.346   \u001b[0m | \u001b[0m 995.3   \u001b[0m | \u001b[0m 88.46   \u001b[0m | \u001b[0m 652.0   \u001b[0m | \u001b[0m 896.1   \u001b[0m | \u001b[0m 928.3   \u001b[0m | \u001b[0m 411.6   \u001b[0m | \u001b[0m 958.0   \u001b[0m | \u001b[0m 35.29   \u001b[0m | \u001b[0m 969.9   \u001b[0m | \u001b[0m 914.3   \u001b[0m | \u001b[0m 351.8   \u001b[0m | \u001b[0m 945.1   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7983  \u001b[0m | \u001b[0m 0.02366 \u001b[0m | \u001b[0m 759.7   \u001b[0m | \u001b[0m 862.6   \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 996.9   \u001b[0m | \u001b[0m 139.0   \u001b[0m | \u001b[0m 21.9    \u001b[0m | \u001b[0m 11.85   \u001b[0m | \u001b[0m 282.7   \u001b[0m | \u001b[0m 463.8   \u001b[0m | \u001b[0m 840.4   \u001b[0m | \u001b[0m 809.5   \u001b[0m | \u001b[0m 908.3   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5871  \u001b[0m | \u001b[0m 304.2   \u001b[0m | \u001b[0m 144.8   \u001b[0m | \u001b[0m 973.3   \u001b[0m | \u001b[0m 232.8   \u001b[0m | \u001b[0m 899.4   \u001b[0m | \u001b[0m 813.1   \u001b[0m | \u001b[0m 899.4   \u001b[0m | \u001b[0m 38.65   \u001b[0m | \u001b[0m 715.5   \u001b[0m | \u001b[0m 69.09   \u001b[0m | \u001b[0m 297.5   \u001b[0m | \u001b[0m 30.72   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1512  \u001b[0m | \u001b[0m 100.2   \u001b[0m | \u001b[0m 8.182   \u001b[0m | \u001b[0m 812.4   \u001b[0m | \u001b[0m 7.725   \u001b[0m | \u001b[0m 743.0   \u001b[0m | \u001b[0m 124.4   \u001b[0m | \u001b[0m 938.1   \u001b[0m | \u001b[0m 187.2   \u001b[0m | \u001b[0m 943.4   \u001b[0m | \u001b[0m 261.0   \u001b[0m | \u001b[0m 20.76   \u001b[0m | \u001b[0m 552.9   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.6965  \u001b[0m | \u001b[0m 361.2   \u001b[0m | \u001b[0m 136.3   \u001b[0m | \u001b[0m 910.4   \u001b[0m | \u001b[0m 262.8   \u001b[0m | \u001b[0m 968.8   \u001b[0m | \u001b[0m 943.1   \u001b[0m | \u001b[0m 993.5   \u001b[0m | \u001b[0m 966.8   \u001b[0m | \u001b[0m 999.6   \u001b[0m | \u001b[0m 654.9   \u001b[0m | \u001b[0m 989.2   \u001b[0m | \u001b[0m 425.9   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 193.7   \u001b[0m | \u001b[0m 70.13   \u001b[0m | \u001b[0m 806.5   \u001b[0m | \u001b[0m 842.9   \u001b[0m | \u001b[0m 822.8   \u001b[0m | \u001b[0m 773.9   \u001b[0m | \u001b[0m 37.89   \u001b[0m | \u001b[0m 850.9   \u001b[0m | \u001b[0m 988.2   \u001b[0m | \u001b[0m 38.55   \u001b[0m | \u001b[0m 2.052   \u001b[0m | \u001b[0m 78.82   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 2.653   \u001b[0m | \u001b[0m 239.0   \u001b[0m | \u001b[0m 7.629   \u001b[0m | \u001b[0m 28.33   \u001b[0m | \u001b[0m 950.4   \u001b[0m | \u001b[0m 784.6   \u001b[0m | \u001b[0m 924.5   \u001b[0m | \u001b[0m 93.65   \u001b[0m | \u001b[0m 969.9   \u001b[0m | \u001b[0m 154.4   \u001b[0m | \u001b[0m 293.4   \u001b[0m | \u001b[0m 269.8   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1934  \u001b[0m | \u001b[0m 643.9   \u001b[0m | \u001b[0m 959.1   \u001b[0m | \u001b[0m 797.9   \u001b[0m | \u001b[0m 132.4   \u001b[0m | \u001b[0m 814.7   \u001b[0m | \u001b[0m 975.9   \u001b[0m | \u001b[0m 986.7   \u001b[0m | \u001b[0m 173.3   \u001b[0m | \u001b[0m 982.8   \u001b[0m | \u001b[0m 231.2   \u001b[0m | \u001b[0m 80.65   \u001b[0m | \u001b[0m 951.6   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7568  \u001b[0m | \u001b[0m 86.04   \u001b[0m | \u001b[0m 843.4   \u001b[0m | \u001b[0m 997.5   \u001b[0m | \u001b[0m 49.28   \u001b[0m | \u001b[0m 373.0   \u001b[0m | \u001b[0m 205.6   \u001b[0m | \u001b[0m 939.3   \u001b[0m | \u001b[0m 882.6   \u001b[0m | \u001b[0m 953.0   \u001b[0m | \u001b[0m 109.4   \u001b[0m | \u001b[0m 9.165   \u001b[0m | \u001b[0m 7.441   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.6069  \u001b[0m | \u001b[0m 92.4    \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 954.1   \u001b[0m | \u001b[0m 987.7   \u001b[0m | \u001b[0m 926.8   \u001b[0m | \u001b[0m 257.2   \u001b[0m | \u001b[0m 161.1   \u001b[0m | \u001b[0m 913.6   \u001b[0m | \u001b[0m 901.7   \u001b[0m | \u001b[0m 85.27   \u001b[0m | \u001b[0m 782.2   \u001b[0m | \u001b[0m 936.7   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5849  \u001b[0m | \u001b[0m 111.6   \u001b[0m | \u001b[0m 857.8   \u001b[0m | \u001b[0m 951.6   \u001b[0m | \u001b[0m 91.1    \u001b[0m | \u001b[0m 208.1   \u001b[0m | \u001b[0m 998.1   \u001b[0m | \u001b[0m 994.2   \u001b[0m | \u001b[0m 36.79   \u001b[0m | \u001b[0m 985.9   \u001b[0m | \u001b[0m 480.7   \u001b[0m | \u001b[0m 987.0   \u001b[0m | \u001b[0m 451.9   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.4248  \u001b[0m | \u001b[0m 3.851   \u001b[0m | \u001b[0m 285.1   \u001b[0m | \u001b[0m 113.9   \u001b[0m | \u001b[0m 956.3   \u001b[0m | \u001b[0m 45.48   \u001b[0m | \u001b[0m 849.9   \u001b[0m | \u001b[0m 979.6   \u001b[0m | \u001b[0m 993.0   \u001b[0m | \u001b[0m 506.9   \u001b[0m | \u001b[0m 707.5   \u001b[0m | \u001b[0m 31.35   \u001b[0m | \u001b[0m 30.76   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 0.9986  \u001b[0m | \u001b[0m 46.47   \u001b[0m | \u001b[0m 880.5   \u001b[0m | \u001b[0m 697.2   \u001b[0m | \u001b[0m 923.6   \u001b[0m | \u001b[0m 812.9   \u001b[0m | \u001b[0m 929.4   \u001b[0m | \u001b[0m 998.3   \u001b[0m | \u001b[0m 912.9   \u001b[0m | \u001b[0m 987.3   \u001b[0m | \u001b[0m 893.3   \u001b[0m | \u001b[0m 652.4   \u001b[0m | \u001b[0m 701.0   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7009  \u001b[0m | \u001b[0m 986.0   \u001b[0m | \u001b[0m 20.2    \u001b[0m | \u001b[0m 675.0   \u001b[0m | \u001b[0m 105.1   \u001b[0m | \u001b[0m 992.8   \u001b[0m | \u001b[0m 753.5   \u001b[0m | \u001b[0m 176.3   \u001b[0m | \u001b[0m 213.7   \u001b[0m | \u001b[0m 948.8   \u001b[0m | \u001b[0m 997.0   \u001b[0m | \u001b[0m 59.67   \u001b[0m | \u001b[0m 10.03   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.655   \u001b[0m | \u001b[0m 212.9   \u001b[0m | \u001b[0m 348.3   \u001b[0m | \u001b[0m 770.6   \u001b[0m | \u001b[0m 483.6   \u001b[0m | \u001b[0m 984.9   \u001b[0m | \u001b[0m 79.39   \u001b[0m | \u001b[0m 985.2   \u001b[0m | \u001b[0m 866.2   \u001b[0m | \u001b[0m 990.2   \u001b[0m | \u001b[0m 815.1   \u001b[0m | \u001b[0m 121.2   \u001b[0m | \u001b[0m 766.6   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2323  \u001b[0m | \u001b[0m 384.1   \u001b[0m | \u001b[0m 226.5   \u001b[0m | \u001b[0m 824.9   \u001b[0m | \u001b[0m 162.3   \u001b[0m | \u001b[0m 367.9   \u001b[0m | \u001b[0m 284.4   \u001b[0m | \u001b[0m 669.4   \u001b[0m | \u001b[0m 66.03   \u001b[0m | \u001b[0m 451.1   \u001b[0m | \u001b[0m 669.5   \u001b[0m | \u001b[0m 265.1   \u001b[0m | \u001b[0m 432.4   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3906  \u001b[0m | \u001b[0m 818.8   \u001b[0m | \u001b[0m 974.7   \u001b[0m | \u001b[0m 995.6   \u001b[0m | \u001b[0m 996.7   \u001b[0m | \u001b[0m 860.7   \u001b[0m | \u001b[0m 54.59   \u001b[0m | \u001b[0m 983.6   \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 834.3   \u001b[0m | \u001b[0m 927.2   \u001b[0m | \u001b[0m 205.2   \u001b[0m | \u001b[0m 822.9   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.4675  \u001b[0m | \u001b[0m 518.1   \u001b[0m | \u001b[0m 14.94   \u001b[0m | \u001b[0m 316.1   \u001b[0m | \u001b[0m 983.4   \u001b[0m | \u001b[0m 106.7   \u001b[0m | \u001b[0m 960.0   \u001b[0m | \u001b[0m 877.3   \u001b[0m | \u001b[0m 552.7   \u001b[0m | \u001b[0m 997.3   \u001b[0m | \u001b[0m 30.33   \u001b[0m | \u001b[0m 252.2   \u001b[0m | \u001b[0m 122.1   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8701  \u001b[0m | \u001b[0m 562.4   \u001b[0m | \u001b[0m 338.9   \u001b[0m | \u001b[0m 62.43   \u001b[0m | \u001b[0m 960.0   \u001b[0m | \u001b[0m 738.5   \u001b[0m | \u001b[0m 79.01   \u001b[0m | \u001b[0m 992.6   \u001b[0m | \u001b[0m 330.4   \u001b[0m | \u001b[0m 205.2   \u001b[0m | \u001b[0m 54.1    \u001b[0m | \u001b[0m 463.2   \u001b[0m | \u001b[0m 620.9   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.07515 \u001b[0m | \u001b[0m 59.78   \u001b[0m | \u001b[0m 813.1   \u001b[0m | \u001b[0m 63.97   \u001b[0m | \u001b[0m 978.3   \u001b[0m | \u001b[0m 425.7   \u001b[0m | \u001b[0m 463.6   \u001b[0m | \u001b[0m 993.9   \u001b[0m | \u001b[0m 195.4   \u001b[0m | \u001b[0m 997.5   \u001b[0m | \u001b[0m 78.0    \u001b[0m | \u001b[0m 47.95   \u001b[0m | \u001b[0m 950.6   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.07843 \u001b[0m | \u001b[0m 464.8   \u001b[0m | \u001b[0m 167.3   \u001b[0m | \u001b[0m 261.3   \u001b[0m | \u001b[0m 907.2   \u001b[0m | \u001b[0m 83.01   \u001b[0m | \u001b[0m 860.7   \u001b[0m | \u001b[0m 965.7   \u001b[0m | \u001b[0m 474.9   \u001b[0m | \u001b[0m 975.6   \u001b[0m | \u001b[0m 101.8   \u001b[0m | \u001b[0m 570.8   \u001b[0m | \u001b[0m 108.3   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7158  \u001b[0m | \u001b[0m 610.9   \u001b[0m | \u001b[0m 303.5   \u001b[0m | \u001b[0m 970.7   \u001b[0m | \u001b[0m 9.268   \u001b[0m | \u001b[0m 26.95   \u001b[0m | \u001b[0m 209.8   \u001b[0m | \u001b[0m 876.4   \u001b[0m | \u001b[0m 648.5   \u001b[0m | \u001b[0m 962.4   \u001b[0m | \u001b[0m 975.9   \u001b[0m | \u001b[0m 198.8   \u001b[0m | \u001b[0m 976.4   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2609  \u001b[0m | \u001b[0m 19.11   \u001b[0m | \u001b[0m 39.68   \u001b[0m | \u001b[0m 998.0   \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 810.3   \u001b[0m | \u001b[0m 499.7   \u001b[0m | \u001b[0m 902.8   \u001b[0m | \u001b[0m 36.13   \u001b[0m | \u001b[0m 42.8    \u001b[0m | \u001b[0m 859.3   \u001b[0m | \u001b[0m 6.059   \u001b[0m | \u001b[0m 414.0   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5587  \u001b[0m | \u001b[0m 163.2   \u001b[0m | \u001b[0m 46.1    \u001b[0m | \u001b[0m 996.1   \u001b[0m | \u001b[0m 895.5   \u001b[0m | \u001b[0m 673.3   \u001b[0m | \u001b[0m 968.5   \u001b[0m | \u001b[0m 236.9   \u001b[0m | \u001b[0m 354.0   \u001b[0m | \u001b[0m 943.6   \u001b[0m | \u001b[0m 968.9   \u001b[0m | \u001b[0m 222.2   \u001b[0m | \u001b[0m 26.12   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.9012  \u001b[0m | \u001b[0m 579.2   \u001b[0m | \u001b[0m 45.51   \u001b[0m | \u001b[0m 134.6   \u001b[0m | \u001b[0m 273.7   \u001b[0m | \u001b[0m 673.8   \u001b[0m | \u001b[0m 70.92   \u001b[0m | \u001b[0m 443.6   \u001b[0m | \u001b[0m 887.3   \u001b[0m | \u001b[0m 664.1   \u001b[0m | \u001b[0m 348.5   \u001b[0m | \u001b[0m 555.9   \u001b[0m | \u001b[0m 678.9   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.4771  \u001b[0m | \u001b[0m 29.61   \u001b[0m | \u001b[0m 45.35   \u001b[0m | \u001b[0m 125.5   \u001b[0m | \u001b[0m 5.475   \u001b[0m | \u001b[0m 882.1   \u001b[0m | \u001b[0m 968.9   \u001b[0m | \u001b[0m 252.7   \u001b[0m | \u001b[0m 187.0   \u001b[0m | \u001b[0m 941.0   \u001b[0m | \u001b[0m 967.1   \u001b[0m | \u001b[0m 875.4   \u001b[0m | \u001b[0m 902.9   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 0.9592  \u001b[0m | \u001b[0m 101.3   \u001b[0m | \u001b[0m 89.83   \u001b[0m | \u001b[0m 886.8   \u001b[0m | \u001b[0m 105.8   \u001b[0m | \u001b[0m 18.61   \u001b[0m | \u001b[0m 789.5   \u001b[0m | \u001b[0m 894.6   \u001b[0m | \u001b[0m 26.25   \u001b[0m | \u001b[0m 919.4   \u001b[0m | \u001b[0m 872.6   \u001b[0m | \u001b[0m 87.41   \u001b[0m | \u001b[0m 876.0   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3006  \u001b[0m | \u001b[0m 840.7   \u001b[0m | \u001b[0m 218.4   \u001b[0m | \u001b[0m 26.49   \u001b[0m | \u001b[0m 114.4   \u001b[0m | \u001b[0m 121.2   \u001b[0m | \u001b[0m 1.88    \u001b[0m | \u001b[0m 887.2   \u001b[0m | \u001b[0m 25.37   \u001b[0m | \u001b[0m 988.6   \u001b[0m | \u001b[0m 185.3   \u001b[0m | \u001b[0m 952.5   \u001b[0m | \u001b[0m 329.6   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1475  \u001b[0m | \u001b[0m 6.537   \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 869.6   \u001b[0m | \u001b[0m 627.8   \u001b[0m | \u001b[0m 373.4   \u001b[0m | \u001b[0m 86.69   \u001b[0m | \u001b[0m 940.3   \u001b[0m | \u001b[0m 121.6   \u001b[0m | \u001b[0m 948.0   \u001b[0m | \u001b[0m 227.9   \u001b[0m | \u001b[0m 45.7    \u001b[0m | \u001b[0m 39.21   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.9467  \u001b[0m | \u001b[0m 38.99   \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 986.6   \u001b[0m | \u001b[0m 23.28   \u001b[0m | \u001b[0m 911.9   \u001b[0m | \u001b[0m 372.7   \u001b[0m | \u001b[0m 365.2   \u001b[0m | \u001b[0m 921.7   \u001b[0m | \u001b[0m 177.7   \u001b[0m | \u001b[0m 16.99   \u001b[0m | \u001b[0m 970.1   \u001b[0m | \u001b[0m 998.0   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1225  \u001b[0m | \u001b[0m 977.8   \u001b[0m | \u001b[0m 42.05   \u001b[0m | \u001b[0m 705.7   \u001b[0m | \u001b[0m 90.74   \u001b[0m | \u001b[0m 928.4   \u001b[0m | \u001b[0m 204.9   \u001b[0m | \u001b[0m 963.4   \u001b[0m | \u001b[0m 767.2   \u001b[0m | \u001b[0m 892.8   \u001b[0m | \u001b[0m 989.2   \u001b[0m | \u001b[0m 31.87   \u001b[0m | \u001b[0m 369.8   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.141   \u001b[0m | \u001b[0m 2.227   \u001b[0m | \u001b[0m 42.95   \u001b[0m | \u001b[0m 867.7   \u001b[0m | \u001b[0m 81.81   \u001b[0m | \u001b[0m 949.6   \u001b[0m | \u001b[0m 918.8   \u001b[0m | \u001b[0m 916.8   \u001b[0m | \u001b[0m 18.8    \u001b[0m | \u001b[0m 866.6   \u001b[0m | \u001b[0m 992.1   \u001b[0m | \u001b[0m 713.3   \u001b[0m | \u001b[0m 102.8   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8536  \u001b[0m | \u001b[0m 454.3   \u001b[0m | \u001b[0m 608.8   \u001b[0m | \u001b[0m 830.6   \u001b[0m | \u001b[0m 118.7   \u001b[0m | \u001b[0m 936.2   \u001b[0m | \u001b[0m 53.97   \u001b[0m | \u001b[0m 979.0   \u001b[0m | \u001b[0m 459.1   \u001b[0m | \u001b[0m 988.0   \u001b[0m | \u001b[0m 874.9   \u001b[0m | \u001b[0m 988.4   \u001b[0m | \u001b[0m 223.6   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8086  \u001b[0m | \u001b[0m 754.9   \u001b[0m | \u001b[0m 972.8   \u001b[0m | \u001b[0m 766.4   \u001b[0m | \u001b[0m 108.4   \u001b[0m | \u001b[0m 37.63   \u001b[0m | \u001b[0m 959.2   \u001b[0m | \u001b[0m 940.5   \u001b[0m | \u001b[0m 971.0   \u001b[0m | \u001b[0m 904.6   \u001b[0m | \u001b[0m 48.09   \u001b[0m | \u001b[0m 933.3   \u001b[0m | \u001b[0m 942.7   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.8026  \u001b[0m | \u001b[0m 789.2   \u001b[0m | \u001b[0m 10.63   \u001b[0m | \u001b[0m 816.6   \u001b[0m | \u001b[0m 898.0   \u001b[0m | \u001b[0m 803.6   \u001b[0m | \u001b[0m 911.4   \u001b[0m | \u001b[0m 974.5   \u001b[0m | \u001b[0m 32.32   \u001b[0m | \u001b[0m 930.0   \u001b[0m | \u001b[0m 876.9   \u001b[0m | \u001b[0m 120.5   \u001b[0m | \u001b[0m 17.41   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 204.7   \u001b[0m | \u001b[0m 672.1   \u001b[0m | \u001b[0m 668.7   \u001b[0m | \u001b[0m 7.748   \u001b[0m | \u001b[0m 959.0   \u001b[0m | \u001b[0m 37.23   \u001b[0m | \u001b[0m 51.14   \u001b[0m | \u001b[0m 37.26   \u001b[0m | \u001b[0m 967.7   \u001b[0m | \u001b[0m 10.96   \u001b[0m | \u001b[0m 723.1   \u001b[0m | \u001b[0m 151.4   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7995  \u001b[0m | \u001b[0m 0.03244 \u001b[0m | \u001b[0m 309.8   \u001b[0m | \u001b[0m 249.9   \u001b[0m | \u001b[0m 586.5   \u001b[0m | \u001b[0m 242.2   \u001b[0m | \u001b[0m 385.0   \u001b[0m | \u001b[0m 282.0   \u001b[0m | \u001b[0m 772.5   \u001b[0m | \u001b[0m 159.6   \u001b[0m | \u001b[0m 710.1   \u001b[0m | \u001b[0m 634.4   \u001b[0m | \u001b[0m 164.8   \u001b[0m | \u001b[0m 351.5   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.8004  \u001b[0m | \u001b[0m 0.04345 \u001b[0m | \u001b[0m 67.79   \u001b[0m | \u001b[0m 72.26   \u001b[0m | \u001b[0m 284.2   \u001b[0m | \u001b[0m 89.04   \u001b[0m | \u001b[0m 859.5   \u001b[0m | \u001b[0m 975.4   \u001b[0m | \u001b[0m 24.24   \u001b[0m | \u001b[0m 847.2   \u001b[0m | \u001b[0m 975.9   \u001b[0m | \u001b[0m 7.05    \u001b[0m | \u001b[0m 167.9   \u001b[0m | \u001b[0m 577.3   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1214  \u001b[0m | \u001b[0m 594.5   \u001b[0m | \u001b[0m 299.6   \u001b[0m | \u001b[0m 911.8   \u001b[0m | \u001b[0m 594.4   \u001b[0m | \u001b[0m 678.2   \u001b[0m | \u001b[0m 533.9   \u001b[0m | \u001b[0m 725.1   \u001b[0m | \u001b[0m 284.6   \u001b[0m | \u001b[0m 524.8   \u001b[0m | \u001b[0m 959.3   \u001b[0m | \u001b[0m 818.1   \u001b[0m | \u001b[0m 626.7   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.01479 \u001b[0m | \u001b[0m 957.8   \u001b[0m | \u001b[0m 726.3   \u001b[0m | \u001b[0m 904.0   \u001b[0m | \u001b[0m 88.63   \u001b[0m | \u001b[0m 564.2   \u001b[0m | \u001b[0m 60.39   \u001b[0m | \u001b[0m 974.7   \u001b[0m | \u001b[0m 937.2   \u001b[0m | \u001b[0m 987.9   \u001b[0m | \u001b[0m 259.3   \u001b[0m | \u001b[0m 975.1   \u001b[0m | \u001b[0m 60.21   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2221  \u001b[0m | \u001b[0m 97.46   \u001b[0m | \u001b[0m 422.8   \u001b[0m | \u001b[0m 923.5   \u001b[0m | \u001b[0m 918.2   \u001b[0m | \u001b[0m 956.6   \u001b[0m | \u001b[0m 649.7   \u001b[0m | \u001b[0m 859.7   \u001b[0m | \u001b[0m 79.65   \u001b[0m | \u001b[0m 979.8   \u001b[0m | \u001b[0m 996.9   \u001b[0m | \u001b[0m 313.4   \u001b[0m | \u001b[0m 956.7   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5751  \u001b[0m | \u001b[0m 70.73   \u001b[0m | \u001b[0m 7.529   \u001b[0m | \u001b[0m 890.3   \u001b[0m | \u001b[0m 993.0   \u001b[0m | \u001b[0m 248.4   \u001b[0m | \u001b[0m 950.6   \u001b[0m | \u001b[0m 269.2   \u001b[0m | \u001b[0m 888.1   \u001b[0m | \u001b[0m 100.8   \u001b[0m | \u001b[0m 865.1   \u001b[0m | \u001b[0m 47.77   \u001b[0m | \u001b[0m 515.0   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 0.9643  \u001b[0m | \u001b[0m 642.5   \u001b[0m | \u001b[0m 47.97   \u001b[0m | \u001b[0m 252.1   \u001b[0m | \u001b[0m 61.13   \u001b[0m | \u001b[0m 268.7   \u001b[0m | \u001b[0m 57.09   \u001b[0m | \u001b[0m 365.1   \u001b[0m | \u001b[0m 398.3   \u001b[0m | \u001b[0m 388.7   \u001b[0m | \u001b[0m 468.9   \u001b[0m | \u001b[0m 498.0   \u001b[0m | \u001b[0m 175.6   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.4385  \u001b[0m | \u001b[0m 26.66   \u001b[0m | \u001b[0m 921.6   \u001b[0m | \u001b[0m 877.8   \u001b[0m | \u001b[0m 912.2   \u001b[0m | \u001b[0m 961.2   \u001b[0m | \u001b[0m 869.7   \u001b[0m | \u001b[0m 990.1   \u001b[0m | \u001b[0m 231.5   \u001b[0m | \u001b[0m 689.8   \u001b[0m | \u001b[0m 841.6   \u001b[0m | \u001b[0m 330.6   \u001b[0m | \u001b[0m 973.4   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5052  \u001b[0m | \u001b[0m 6.914   \u001b[0m | \u001b[0m 58.86   \u001b[0m | \u001b[0m 29.86   \u001b[0m | \u001b[0m 989.9   \u001b[0m | \u001b[0m 232.4   \u001b[0m | \u001b[0m 958.3   \u001b[0m | \u001b[0m 504.9   \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 812.9   \u001b[0m | \u001b[0m 185.7   \u001b[0m | \u001b[0m 149.7   \u001b[0m | \u001b[0m 936.8   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3702  \u001b[0m | \u001b[0m 75.05   \u001b[0m | \u001b[0m 22.1    \u001b[0m | \u001b[0m 818.7   \u001b[0m | \u001b[0m 3.603   \u001b[0m | \u001b[0m 157.9   \u001b[0m | \u001b[0m 194.4   \u001b[0m | \u001b[0m 982.8   \u001b[0m | \u001b[0m 572.3   \u001b[0m | \u001b[0m 296.0   \u001b[0m | \u001b[0m 993.1   \u001b[0m | \u001b[0m 70.82   \u001b[0m | \u001b[0m 842.7   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2614  \u001b[0m | \u001b[0m 4.919   \u001b[0m | \u001b[0m 946.8   \u001b[0m | \u001b[0m 276.3   \u001b[0m | \u001b[0m 1.821   \u001b[0m | \u001b[0m 155.5   \u001b[0m | \u001b[0m 936.8   \u001b[0m | \u001b[0m 975.3   \u001b[0m | \u001b[0m 993.2   \u001b[0m | \u001b[0m 195.5   \u001b[0m | \u001b[0m 971.5   \u001b[0m | \u001b[0m 804.0   \u001b[0m | \u001b[0m 927.3   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.07495 \u001b[0m | \u001b[0m 128.4   \u001b[0m | \u001b[0m 24.52   \u001b[0m | \u001b[0m 89.14   \u001b[0m | \u001b[0m 184.7   \u001b[0m | \u001b[0m 35.13   \u001b[0m | \u001b[0m 71.27   \u001b[0m | \u001b[0m 997.5   \u001b[0m | \u001b[0m 129.0   \u001b[0m | \u001b[0m 178.8   \u001b[0m | \u001b[0m 672.5   \u001b[0m | \u001b[0m 29.82   \u001b[0m | \u001b[0m 653.2   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5037  \u001b[0m | \u001b[0m 47.55   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 882.0   \u001b[0m | \u001b[0m 939.7   \u001b[0m | \u001b[0m 44.53   \u001b[0m | \u001b[0m 825.6   \u001b[0m | \u001b[0m 217.8   \u001b[0m | \u001b[0m 210.5   \u001b[0m | \u001b[0m 32.59   \u001b[0m | \u001b[0m 36.1    \u001b[0m | \u001b[0m 695.0   \u001b[0m | \u001b[0m 811.0   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 870.5   \u001b[0m | \u001b[0m 324.1   \u001b[0m | \u001b[0m 500.5   \u001b[0m | \u001b[0m 911.5   \u001b[0m | \u001b[0m 11.77   \u001b[0m | \u001b[0m 160.7   \u001b[0m | \u001b[0m 3.123   \u001b[0m | \u001b[0m 629.4   \u001b[0m | \u001b[0m 932.7   \u001b[0m | \u001b[0m 128.3   \u001b[0m | \u001b[0m 883.9   \u001b[0m | \u001b[0m 892.7   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 746.8   \u001b[0m | \u001b[0m 15.38   \u001b[0m | \u001b[0m 185.1   \u001b[0m | \u001b[0m 917.4   \u001b[0m | \u001b[0m 993.5   \u001b[0m | \u001b[0m 986.4   \u001b[0m | \u001b[0m 916.4   \u001b[0m | \u001b[0m 133.8   \u001b[0m | \u001b[0m 982.9   \u001b[0m | \u001b[0m 183.9   \u001b[0m | \u001b[0m 30.94   \u001b[0m | \u001b[0m 900.1   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7994  \u001b[0m | \u001b[0m 0.03099 \u001b[0m | \u001b[0m 45.81   \u001b[0m | \u001b[0m 20.78   \u001b[0m | \u001b[0m 898.7   \u001b[0m | \u001b[0m 466.5   \u001b[0m | \u001b[0m 307.4   \u001b[0m | \u001b[0m 955.9   \u001b[0m | \u001b[0m 660.4   \u001b[0m | \u001b[0m 31.39   \u001b[0m | \u001b[0m 277.5   \u001b[0m | \u001b[0m 30.41   \u001b[0m | \u001b[0m 22.73   \u001b[0m | \u001b[0m 976.7   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 0.9638  \u001b[0m | \u001b[0m 51.32   \u001b[0m | \u001b[0m 174.3   \u001b[0m | \u001b[0m 141.4   \u001b[0m | \u001b[0m 950.0   \u001b[0m | \u001b[0m 859.1   \u001b[0m | \u001b[0m 706.2   \u001b[0m | \u001b[0m 581.4   \u001b[0m | \u001b[0m 67.3    \u001b[0m | \u001b[0m 824.9   \u001b[0m | \u001b[0m 894.4   \u001b[0m | \u001b[0m 884.6   \u001b[0m | \u001b[0m 52.32   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.5796  \u001b[0m | \u001b[0m 188.5   \u001b[0m | \u001b[0m 979.2   \u001b[0m | \u001b[0m 843.7   \u001b[0m | \u001b[0m 965.4   \u001b[0m | \u001b[0m 270.2   \u001b[0m | \u001b[0m 953.5   \u001b[0m | \u001b[0m 167.5   \u001b[0m | \u001b[0m 5.463   \u001b[0m | \u001b[0m 871.9   \u001b[0m | \u001b[0m 129.2   \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 29.05   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.6357  \u001b[0m | \u001b[0m 298.1   \u001b[0m | \u001b[0m 18.68   \u001b[0m | \u001b[0m 373.9   \u001b[0m | \u001b[0m 793.3   \u001b[0m | \u001b[0m 576.1   \u001b[0m | \u001b[0m 56.52   \u001b[0m | \u001b[0m 234.8   \u001b[0m | \u001b[0m 958.7   \u001b[0m | \u001b[0m 972.6   \u001b[0m | \u001b[0m 912.8   \u001b[0m | \u001b[0m 44.17   \u001b[0m | \u001b[0m 922.6   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.9075  \u001b[0m | \u001b[0m 21.11   \u001b[0m | \u001b[0m 41.38   \u001b[0m | \u001b[0m 884.9   \u001b[0m | \u001b[0m 985.1   \u001b[0m | \u001b[0m 903.3   \u001b[0m | \u001b[0m 70.17   \u001b[0m | \u001b[0m 807.6   \u001b[0m | \u001b[0m 97.45   \u001b[0m | \u001b[0m 560.7   \u001b[0m | \u001b[0m 846.6   \u001b[0m | \u001b[0m 830.3   \u001b[0m | \u001b[0m 622.8   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.1547  \u001b[0m | \u001b[0m 83.09   \u001b[0m | \u001b[0m 51.97   \u001b[0m | \u001b[0m 95.94   \u001b[0m | \u001b[0m 115.1   \u001b[0m | \u001b[0m 21.64   \u001b[0m | \u001b[0m 976.3   \u001b[0m | \u001b[0m 976.5   \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 232.6   \u001b[0m | \u001b[0m 982.1   \u001b[0m | \u001b[0m 125.9   \u001b[0m | \u001b[0m 771.0   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3769  \u001b[0m | \u001b[0m 87.23   \u001b[0m | \u001b[0m 94.88   \u001b[0m | \u001b[0m 95.52   \u001b[0m | \u001b[0m 24.36   \u001b[0m | \u001b[0m 798.1   \u001b[0m | \u001b[0m 9.311   \u001b[0m | \u001b[0m 30.47   \u001b[0m | \u001b[0m 474.0   \u001b[0m | \u001b[0m 824.7   \u001b[0m | \u001b[0m 894.9   \u001b[0m | \u001b[0m 989.6   \u001b[0m | \u001b[0m 997.6   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.41    \u001b[0m | \u001b[0m 55.47   \u001b[0m | \u001b[0m 988.3   \u001b[0m | \u001b[0m 20.08   \u001b[0m | \u001b[0m 73.78   \u001b[0m | \u001b[0m 758.2   \u001b[0m | \u001b[0m 942.0   \u001b[0m | \u001b[0m 918.1   \u001b[0m | \u001b[0m 624.5   \u001b[0m | \u001b[0m 558.7   \u001b[0m | \u001b[0m 958.6   \u001b[0m | \u001b[0m 137.8   \u001b[0m | \u001b[0m 724.4   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 0.2852  \u001b[0m | \u001b[0m 61.92   \u001b[0m | \u001b[0m 43.27   \u001b[0m | \u001b[0m 403.1   \u001b[0m | \u001b[0m 887.5   \u001b[0m | \u001b[0m 24.22   \u001b[0m | \u001b[0m 783.6   \u001b[0m | \u001b[0m 943.4   \u001b[0m | \u001b[0m 964.2   \u001b[0m | \u001b[0m 951.0   \u001b[0m | \u001b[0m 866.7   \u001b[0m | \u001b[0m 431.3   \u001b[0m | \u001b[0m 993.1   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.3813  \u001b[0m | \u001b[0m 925.0   \u001b[0m | \u001b[0m 241.9   \u001b[0m | \u001b[0m 512.6   \u001b[0m | \u001b[0m 715.6   \u001b[0m | \u001b[0m 535.8   \u001b[0m | \u001b[0m 133.3   \u001b[0m | \u001b[0m 600.5   \u001b[0m | \u001b[0m 894.2   \u001b[0m | \u001b[0m 576.7   \u001b[0m | \u001b[0m 513.3   \u001b[0m | \u001b[0m 989.8   \u001b[0m | \u001b[0m 674.8   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.73    \u001b[0m | \u001b[0m 78.75   \u001b[0m | \u001b[0m 188.7   \u001b[0m | \u001b[0m 983.4   \u001b[0m | \u001b[0m 54.41   \u001b[0m | \u001b[0m 38.9    \u001b[0m | \u001b[0m 43.98   \u001b[0m | \u001b[0m 51.37   \u001b[0m | \u001b[0m 278.0   \u001b[0m | \u001b[0m 875.1   \u001b[0m | \u001b[0m 958.5   \u001b[0m | \u001b[0m 942.4   \u001b[0m | \u001b[0m 230.6   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.8013  \u001b[0m | \u001b[0m 0.7362  \u001b[0m | \u001b[0m 4.138   \u001b[0m | \u001b[0m 928.0   \u001b[0m | \u001b[0m 98.61   \u001b[0m | \u001b[0m 838.3   \u001b[0m | \u001b[0m 465.5   \u001b[0m | \u001b[0m 34.74   \u001b[0m | \u001b[0m 29.2    \u001b[0m | \u001b[0m 53.62   \u001b[0m | \u001b[0m 870.6   \u001b[0m | \u001b[0m 104.4   \u001b[0m | \u001b[0m 23.95   \u001b[0m | \u001b[0m 946.6   \u001b[0m |\n",
      "=====================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "bounds_logit = {\n",
    "    'C': (2**-8, 1),\n",
    "    'min_bin_4':(1,1000),\n",
    "    'smoot_bin_4':(1,1000),\n",
    "    'min_nom_2':(1,1000),\n",
    "    'smoot_nom_2':(1,1000),\n",
    "    'min_nom_8':(1,1000),\n",
    "    'smoot_nom_8':(1,1000),\n",
    "    'min_nom_9':(1,1000),\n",
    "    'smoot_nom_9':(1,1000),\n",
    "    'min_ord_1':(1,1000),\n",
    "    'smoot_ord_1':(1,1000),\n",
    "    'min_ord_5':(1,1000),\n",
    "    'smoot_ord_5':(1,1000),\n",
    "}\n",
    "lbg_bayes = BayesianOptimization(logit_bayes, bounds_logit, random_state=1)\n",
    "n_fold=5\n",
    "init_points = 5\n",
    "n_iter = 100\n",
    "print('-' * 127)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    lbg_bayes.maximize(init_points=init_points, n_iter=n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016089992064421"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbg_bayes.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.16750619378151424,\n",
       " 'min_bin_4': 999.278226929541,\n",
       " 'min_nom_2': 998.2264797985416,\n",
       " 'min_nom_8': 478.6201714813315,\n",
       " 'min_nom_9': 932.4114630159186,\n",
       " 'min_ord_1': 998.7815846789609,\n",
       " 'min_ord_5': 929.8586375729484,\n",
       " 'smoot_bin_4': 853.6768869921463,\n",
       " 'smoot_nom_2': 955.674930086958,\n",
       " 'smoot_nom_8': 818.8237255821915,\n",
       " 'smoot_nom_9': 627.6620227252247,\n",
       " 'smoot_ord_1': 857.6148881185935,\n",
       " 'smoot_ord_5': 192.23171998520255}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbg_bayes.max['params']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
